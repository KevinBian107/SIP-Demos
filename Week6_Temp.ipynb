{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499b8cf",
   "metadata": {},
   "source": [
    "# Math 189 Week 6 Summary\n",
    "> NAME: $\\color{blue}{\\text{Kaiwen Bian}}$\n",
    "> \n",
    "> PID: $\\color{blue}{\\text{A17316568}}$\n",
    ">\n",
    "> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce0cf8",
   "metadata": {},
   "source": [
    "I certify that the following write-up is my own work, and have abided by the UCSD Academic Integrity Guidelines.\n",
    "\n",
    "- [x] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c41b1",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$%$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$%$\n",
    "$\\forcecommand{\\supp}{\\text{supp}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\forcecommand{\\var}{\\text{Var}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\ci}{\\text{CI}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0120db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats as stats\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec7ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6dc53",
   "metadata": {},
   "source": [
    "## Key Takeaways from Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f31",
   "metadata": {},
   "source": [
    "\n",
    "#### Tuesday: \n",
    "\n",
    "... insert your key takeaways here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69de7b",
   "metadata": {},
   "source": [
    "#### Thursday\n",
    "\n",
    "... insert your takeaway here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadbca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abad0d9",
   "metadata": {},
   "source": [
    "# Regression Analysis: Quantiative Response & Predictor\n",
    "**We want to quantify what is the  uncertainty is and how to use them in inference.** Regression is a technqiue of both **Predictions**, **Inference**, and also **Analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8c2ea",
   "metadata": {},
   "source": [
    "### Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313ab33",
   "metadata": {},
   "source": [
    "The simple linear regression model assumes that the relationship between the two variables is linear, and can be expressed as:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\beta_0$ and $\\beta_1$ are the intercept and slope of the line, and $\\epsilon_i$ is the error term. The error term captures the difference between the observed value $y_i$ and the value predicted by the model $\\beta_0 + \\beta_1 x_i$. The goal of simple linear regression is to **estimate the values of $\\beta_0$ and $\\beta_1$ that best fit the data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8df81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "402fb517",
   "metadata": {},
   "source": [
    "Residual says that what is the quantity of error that we are making comparing our regression prediction and the actual observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8188d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79db641",
   "metadata": {},
   "source": [
    "The line of best fit is given by the equation:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\n",
    "$$\n",
    "\n",
    "where $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ are the estimated values of the intercept and slope, and $\\hat{y}$ is the predicted value of $y$. **So how can we best estimate these two values of $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6daf1",
   "metadata": {},
   "source": [
    "The method of least squares is used to estimate the values of $\\beta_0$ and $\\beta_1$ that minimize the sum of the squared differences between the observed and predicted values $\\hat{y}$:\n",
    "\n",
    "$$\n",
    "\\text{Loss}(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0, \\hat{\\beta}_1 = \\arg\\min_{\\beta_0 \\in \\mathbb{R}, \\beta_1 \\in \\mathbb{R}} \\text{Loss}(\\beta_0, \\beta_1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f52bb",
   "metadata": {},
   "source": [
    "### Regression Equation In Matrix Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52d679",
   "metadata": {},
   "source": [
    "Let $\\mathbf{x} = (x_1, x_2, \\dots, x_n) \\in \\mathbb{R}^n$ be the vector of independent variables and $\\mathbf{y}$ be the vector of dependent variables, and let $\\mathbf{X}$ be the matrix of the independent variables along with a column of 1â€™s, i.e.,\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then the estimated values of $\\beta_0$ and $\\beta_1$ are given by:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{pmatrix} =\n",
    "(\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y} =\n",
    "\\begin{pmatrix} n & \\sum x_i \\\\ \\sum x_i & \\sum x_i^2 \\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix} \\sum y_i \\\\ \\sum x_i y_i \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118dd49",
   "metadata": {},
   "source": [
    "First interpretation is that the regression is just a minimizor of this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ab325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3c3688",
   "metadata": {},
   "source": [
    "### Estimation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c68e1",
   "metadata": {},
   "source": [
    "The predicted/fitted value of $y$ for a given value of $x$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\begin{bmatrix} 1 & x \\end{bmatrix}\n",
    "\\begin{pmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\hat{\\beta}_0 + \\hat{\\beta}_1 x\n",
    "$$\n",
    "\n",
    "Given a new value $x^*$, the predicted value of $y$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y}^* = \\begin{bmatrix} 1 & x^* \\end{bmatrix}\n",
    "\\begin{pmatrix} \\hat{\\beta}_0 \\\\ \\hat{\\beta}_1 \\end{pmatrix}\n",
    "= \\hat{\\beta}_0 + \\hat{\\beta}_1 x^*\n",
    "$$\n",
    "\n",
    "The residual for the $i$-th observation is the difference between the observed and predicted values of $y$, i.e.,\n",
    "\n",
    "$$\n",
    "e_i = y_i - \\hat{y}_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275217d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ad9867",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bc658",
   "metadata": {},
   "source": [
    "# Interpretation of LR\n",
    "\n",
    "The optimziation problem we have setup previously can be calculated or derived from many forms/methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0be9c",
   "metadata": {},
   "source": [
    "> #### Optimization: Sum of Squares Interpretation\n",
    "It is just an optimziatipn problem!\n",
    "\n",
    "The fitted regression equation \\( y = \\hat{\\beta}_0 + \\hat{\\beta}_1 x \\) can be interpreted as the best linear approximation to the relationship between \\( x \\) and \\( y \\) in terms of minimizing the sum of squares of the residuals, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0, \\hat{\\beta}_1 = \\min_{\\beta_0 \\in \\mathbb{R}, \\beta_1 \\in \\mathbb{R}} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_0, \\hat{\\beta}_1 = \\min_{\\beta_0 \\in \\mathbb{R}, \\beta_1 \\in \\mathbb{R}} \\sum_{i=1}^{n} (e_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4a3e2",
   "metadata": {},
   "source": [
    "> #### Correlation: Coefficients Interpretation\n",
    "Correlation coefficient looks at associations between varaibales:\n",
    "\n",
    "The slope of the regression line $\\beta_1$ is a measure of the correlation between the independent and dependent variables, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})^2} = r_{xy} \\cdot \\frac{s_y}{s_x}\n",
    "$$\n",
    "\n",
    "where $s_x$ and $s_y$ are the standard deviations of $x$ and $y$, and $r_{xy}$ is the correlation coefficient between $x$ and $y$ given by:\n",
    "\n",
    "$$\n",
    "r_{xy} = \\frac{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits_{i=1}^{n} (x_i - \\bar{x})^2 \\cdot \\sum\\limits_{i=1}^{n} (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "Regression slope essentially **captures a rescaled version of the correlation between x and y**. It is rescaled by the standadr deviation of x and standard deviation of y.\n",
    "\n",
    "- It is rescale is to to handle the scale differences between variables if they exist on different scale.\n",
    "\n",
    "- There is no optimziation happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a16f88",
   "metadata": {},
   "source": [
    "> #### Probabilistic: MLE Interpretation\n",
    "\n",
    "The simple linear regression model assumes that the relationship between the two variables is linear, and can be expressed as:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "- $\\beta_0$ and $\\beta_1$ are the intercept and slope of the line, and $\\epsilon_i$ is the error term.\n",
    "- The error term captures the difference between the observed value $y_i$ and the value predicted by the model $\\beta_0 + \\beta_1 x_i$.\n",
    "\n",
    "Now suppose the error terms $\\epsilon_i$ are normally distributed with mean 0 and variance $\\sigma^2$, i.e.,\n",
    "\n",
    "$$\n",
    "\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_n \\sim \\mathcal{N}(0, \\sigma^2).\n",
    "$$\n",
    "\n",
    "Then the distribution of the dependent variable $y$ **given** the independent variable $x$ is given by:\n",
    "\n",
    "$$\n",
    "y_i \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_i, \\sigma^2).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a481ebe",
   "metadata": {},
   "source": [
    "If $y_i | x_i \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_i, \\sigma^2)$, the probability density function of $y_i$ given $x_i$ is given by:\n",
    "\n",
    "$$\n",
    "f(y_i | x_i, \\beta_0, \\beta_1, \\sigma^2) =\n",
    "\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n",
    "\\exp\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "and that\n",
    "\n",
    "$$\n",
    "\\log f(y_i | x_i, \\beta_0, \\beta_1, \\sigma^2) =\n",
    "\\log\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right) -\n",
    "\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "The log-likelihood function of the parameters $\\beta_0, \\beta_1,$ and $\\sigma^2$ given the observed data is given by:\n",
    "\n",
    "$$\n",
    "\\ell(\\beta_0, \\beta_1, \\sigma^2 | x, y) = \\sum_{i=1}^{n} \\log f(y_i | x_i, \\beta_0, \\beta_1, \\sigma^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\n",
    "$$\n",
    "\n",
    "This looks very much like the negative of the loss function we had earlier in the optimization interpretation. The maximum likelihood estimates of the parameters $\\beta_0$, $\\beta_1$, and $\\sigma^2$ are given by:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta_0}, \\hat{\\beta_1}, \\hat{\\sigma^2} = \\arg\\max_{\\substack{\\sigma^2 \\in \\mathbb{R}^+ \\\\ \\beta_0 \\in \\mathbb{R} \\\\ \\beta_1 \\in \\mathbb{R}}} \\ell(\\beta_0, \\beta_1, \\sigma^2 | x, y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\arg\\min_{\\substack{\\sigma^2 \\in \\mathbb{R}^+ \\\\ \\beta_0 \\in \\mathbb{R} \\\\ \\beta_1 \\in \\mathbb{R}}} \\left( \\underbrace{\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2}_{\\text{Sum of squares}} - \\frac{n}{2} \\log(2\\pi\\sigma^2) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630259d",
   "metadata": {},
   "source": [
    "From this, we get the same estimates of $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ as before, i.e.,\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \n",
    "\\hat{\\beta}_0 \\\\ \n",
    "\\hat{\\beta}_1 \n",
    "\\end{pmatrix}\n",
    "=\n",
    "(\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "But, we also get an estimate of the variance of the error term $\\hat{\\sigma}^2$ given by:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n - 2} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\frac{1}{n - 2} \\sum_{i=1}^{n} e_i^2\n",
    "$$\n",
    "\n",
    "*(this is actually a REML estimator as opposed to an ML estimator)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a629bc",
   "metadata": {},
   "source": [
    "**It is this perspective of the regression analysis that can allow us to form hypothesis test, confidence intervals, and find $p$-values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1ceb9",
   "metadata": {},
   "source": [
    "### Interpretations of Model & Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ebd14",
   "metadata": {},
   "source": [
    "> #### Interpretation of Model\n",
    "\n",
    "Conditional distribution of y given x:\n",
    "\n",
    "$$\n",
    "y | x \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x, \\sigma^2)\n",
    "$$\n",
    "\n",
    "therefore,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(y | x) = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "and, **based on the data** we have, **our best guess** of $\\mathbb{E}(y | x)$ is given by $\\hat{y}(x)$, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdf05f",
   "metadata": {},
   "source": [
    "> #### Interpretation of Coefficients\n",
    "\n",
    "##### Interpretation of $\\beta_0$:\n",
    "if $x = 0$, then\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(y | x = 0) = \\beta_0\n",
    "$$\n",
    "\n",
    "so,\n",
    "\n",
    "$$\n",
    "\\hat{y}(0) = \\hat{\\beta}_0\n",
    "$$\n",
    "\n",
    "In other words, $\\hat{\\beta}_0$ is the expected value of the dependent variable when $x = 0$.\n",
    "\n",
    "##### Interpretation of $\\beta_1$:\n",
    "\n",
    "Again, back to this model:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(y | x) = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x} \\mathbb{E}(y | x) = \\beta_1\n",
    "$$\n",
    "\n",
    "Therefore, $\\beta_1$ is the expected change in the dependent variable $y$ for an infinitesimal change in the independent variable $x$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x} \\hat{y}(x) = \\hat{\\beta}_1\n",
    "$$\n",
    "\n",
    "And, $\\hat{\\beta}_1$ is our best guess of the expected change in the dependent variable $y$ for an infinitesimal change in the independent variable $x$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5ad21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd893a57",
   "metadata": {},
   "source": [
    "# Anatomy of Regression Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10e689",
   "metadata": {},
   "source": [
    "> #### Significance of Coefficients\n",
    "\n",
    "Each p-value in the summary table is the p-value of the two-sided hypothesis test:\n",
    "\n",
    "$$\n",
    "H_0: \\beta = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: \\beta \\neq 0\n",
    "$$\n",
    "\n",
    "It is a hypotheiss test checking the associations between varaiables (not independent, independent is a **stronger** statement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ea6b57",
   "metadata": {},
   "source": [
    "> #### Predcited Values & Residuals\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79609cf9",
   "metadata": {},
   "source": [
    "> #### Different Sums of Squares\n",
    "\n",
    "In this, we have three important **sums of squares** in the regression model:\n",
    "\n",
    "| **Sum of squares** | **Equation** | **Intuition** |\n",
    "|--------------------|-------------|--------------|\n",
    "| $SS_{\\text{Tot}}$ | $\\sum\\limits_{i=1}^{n} (y_i - \\bar{y})^2$ | How much variability is present in the observed values $y$ |\n",
    "| $SS_{\\text{Reg}}$ | $\\sum\\limits_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2$ | How much variability the regression model $\\hat{y}$ reproduces |\n",
    "| $SS_{\\text{Res}}$ | $\\sum\\limits_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | How much variability in $y$ the regression model $\\hat{y}$ is unable to reproduce |\n",
    "\n",
    "1. **Total sum of squares (TSS):** The sum of the squared differences between the observed values of $y$ and the mean of $y$.\n",
    "\n",
    "2. **Regression sum of squares (RSS):** The sum of the squared differences between the predicted values of $y$ and the mean of $y$. This is how many `total explained variability`.\n",
    "\n",
    "3. **Residual sum of squares (RSS):** The sum of the squared differences between the observed values of $y$ and the predicted values of $y$. This is the `total unexplained variance`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba75d1",
   "metadata": {},
   "source": [
    "> #### R-squared\n",
    "The coefficient of determination $R^2$ is a measure of how well the regression model fits the data, and is given by:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{SS_{\\text{Reg}}}{SS_{\\text{Tot}}}\n",
    "$$\n",
    "\n",
    "Intuitively, $R^2$ is the proportion of the total variability in the dependent variable $y$ that is explained by the regression model.\n",
    "\n",
    "This is the main formula for $R^2$, it **only has the valid interpretation** if you set up an proper linear regression model like the ones we did. You may get a  `negative` $R^2$ if your assumptions of LR is not met.\n",
    "\n",
    "In addition, when the **Pathagorithm triquality** holds:\n",
    "\n",
    "$$\n",
    "SS_{\\text{Tot}} = SS_{\\text{Reg}} + SS_{\\text{Rss}}\n",
    "$$\n",
    "\n",
    "We cna recover the correlation coefficient:\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{SS_{\\text{Tot}} - SS_{\\text{Res}}}{SS_{\\text{Tot}}} = 1 - \\frac{SS_{\\text{Res}}}{SS_{\\text{Tot}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761b417",
   "metadata": {},
   "source": [
    "> #### F-statistic\n",
    "\n",
    "The $F$-statistic is a measure of how well the model explains the variance in the data. It is given by:\n",
    "\n",
    "$$\n",
    "\\hat{F} = \\frac{SS_{\\text{Reg}} / df_{\\text{Reg}}}{SS_{\\text{Res}} / df_{\\text{Res}}}\n",
    "$$\n",
    "\n",
    "The degree of regression is how many covariance, how many independent variables you have in the regression model:\n",
    "\n",
    "$$\n",
    "df_{\\text{Reg}} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "df_{\\text{Res}} = n - 2\n",
    "$$\n",
    "\n",
    "Intuitively, the $F$-statistic is the **ratio** of the explained variance to the unexplained variance in the data.\n",
    "\n",
    "- We try to have $SS_{\\text{Res}}$ to be as low as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61305cb4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b339f8",
   "metadata": {},
   "source": [
    "# F-statistic Hypothesis Test\n",
    "\n",
    "Idea is that there is a Chi-square distribution some where. Maybe we can use it for hypothesis tesing?\n",
    "\n",
    "The $F$-statistic is used to test the null hypothesis that the model is no better than the null model, i.e., the model with no predictors.\n",
    "\n",
    "$$\n",
    "H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: \\text{At least one } \\beta_j \\neq 0\n",
    "$$\n",
    "\n",
    "The $F$-statistic follows an $F(df_{\\text{Reg}}, df_{\\text{Res}})$ distribution under the null hypothesis, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{F} = \\frac{SS_{\\text{Reg}} / df_{\\text{Reg}}}{SS_{\\text{Res}} / df_{\\text{Res}}} \\sim F(df_{\\text{Reg}}, df_{\\text{Res}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59353c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae523a5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8f965",
   "metadata": {},
   "source": [
    "# Diagnostics Via Holding Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e86e8",
   "metadata": {},
   "source": [
    "LR analysis result is very delicate and we need to make sure that **all of the rpevious assumptions are hold**. Here are the main asssumptions of the regression model:\n",
    "\n",
    "1. Errors are `normally distributed`, they are `independent`, they are `identical`\n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b1d87",
   "metadata": {},
   "source": [
    "Here's how I would go about checking these assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c33cc",
   "metadata": {},
   "source": [
    "> ##### Assumption 1 \n",
    "Suppose the error terms $\\epsilon_i$ are normally distributed with mean $0$ and variance $\\sigma^2$, i.e.,\n",
    "\n",
    "$$\n",
    "\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_n \\overset{\\text{i.i.d.}}{\\sim} N(0, \\sigma^2).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2684ef",
   "metadata": {},
   "source": [
    "> ##### Assumption 2\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571454f0",
   "metadata": {},
   "source": [
    "> ##### Assumption 3\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c7daa",
   "metadata": {},
   "source": [
    "> ##### Assumption 4\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74421b83",
   "metadata": {},
   "source": [
    "> ##### Assumption 5\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1d209",
   "metadata": {},
   "source": [
    "### Unusual Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8b8569",
   "metadata": {},
   "source": [
    "> ##### Outliers\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf4991",
   "metadata": {},
   "source": [
    "> ##### Influential points\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15473cf",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06efcaa3",
   "metadata": {},
   "source": [
    "## Thu, May 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5712cb74",
   "metadata": {},
   "source": [
    "# Example Regression: Categorical Rredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e49d0e",
   "metadata": {},
   "source": [
    "##### Visual interpretation of \"regression effect\"\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be153a",
   "metadata": {},
   "source": [
    "##### Regression equation (under the hood)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f30eb",
   "metadata": {},
   "source": [
    "##### Intepretation of the regression coefficients\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d631ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b025551",
   "metadata": {},
   "source": [
    "# Example Regression: Multiple Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d263628",
   "metadata": {},
   "source": [
    "##### Regression equation\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11df14",
   "metadata": {},
   "source": [
    "##### Regression equation (matrix form)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6020e6",
   "metadata": {},
   "source": [
    "##### Estimation procedure\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6676f3",
   "metadata": {},
   "source": [
    "##### Optimal estimates\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab4e41",
   "metadata": {},
   "source": [
    "### Anatomy of the regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d65de",
   "metadata": {},
   "source": [
    "> #### Predicted values\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65350648",
   "metadata": {},
   "source": [
    "> #### Residuals\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc15fd5",
   "metadata": {},
   "source": [
    "> #### Sum of squares\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4159cf",
   "metadata": {},
   "source": [
    "> #### R-squared\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999732f",
   "metadata": {},
   "source": [
    "> #### F-statistic\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9fbbd",
   "metadata": {},
   "source": [
    "> #### Interpretation of coefficients\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2054701",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
