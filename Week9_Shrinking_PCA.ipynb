{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499b8cf",
   "metadata": {},
   "source": [
    "# Math 189 Week 9 Summary\n",
    "> NAME: $\\color{blue}{\\text{Kaiwen Bian}}$\n",
    "> \n",
    "> PID: $\\color{blue}{\\text{A17316568}}$\n",
    ">\n",
    "> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce0cf8",
   "metadata": {},
   "source": [
    "I certify that the following write-up is my own work, and have abided by the UCSD Academic Integrity Guidelines.\n",
    "\n",
    "- [x] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c41b1",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$%$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$%$\n",
    "$\\forcecommand{\\supp}{\\text{supp}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\forcecommand{\\var}{\\text{Var}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\ci}{\\text{CI}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9025a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# pio.renderers.default='notebook'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Optional \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "matplotlib.rcParams['figure.figsize'] = 7, 7\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4b4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def plot_X(X, ax, type='pmf', **kwargs):\n",
    "    ax.set_xlabel('Support')\n",
    "    ax.set_title(f'{X.dist.name}{X.args}')\n",
    "    \n",
    "    min_X, max_X = X.ppf((1e-3, 1-1e-3))\n",
    "    supp_X = np.linspace(min_X-1, max_X + 1, 200)\n",
    "    \n",
    "    if type == 'pmf':\n",
    "        supp_X = np.arange(min_X-1, max_X + 1)\n",
    "        ax.bar(supp_X, X.pmf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PMF')\n",
    "    elif type == 'pdf':\n",
    "        ax.plot(supp_X, X.pdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PDF')\n",
    "    elif type == 'cdf':\n",
    "        ax.plot(supp_X, X.cdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('CDF')\n",
    "    else:\n",
    "        raise ValueError('type must be pmf or cdf')\n",
    "\n",
    "def decision(pvalue, alpha):\n",
    "    if pvalue < alpha:\n",
    "        print(f'reject H0: pvalue={pvalue} < {alpha}')  \n",
    "    else: \n",
    "        print(f'fail to reject H0: pvalue={pvalue} â‰¥ {alpha}')\n",
    "\n",
    "def standardize(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "\n",
    "def make_data(errors):\n",
    "    n = len(errors)\n",
    "    x1 = np.linspace(0, 1, n)\n",
    "    x2 = np.random.rand(n)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'x1': x1, \n",
    "        'x2': x2, \n",
    "        'y': 2 + 3*x1 + 4*x2 + errors\n",
    "    })\n",
    "\n",
    "def plot_regression(data, fit, residuals=True):\n",
    "    b = fit.params\n",
    "    b0, b1, b2 = *b, *np.zeros(3 - len(b))\n",
    "    y, x1, x2 = data.y, data.x1, data.x2\n",
    "    fig = px.scatter_3d(x=x1, y=x2, z=y)\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis_title='X1',\n",
    "            yaxis_title='X2',\n",
    "            zaxis_title='Y'),\n",
    "            margin=dict(l=0, r=0, b=0, t=0\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    \n",
    "    x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "    yhat = b0 + (b1 * x1_grid) + (b2 * x2_grid)\n",
    "    fig.add_trace(\n",
    "        go.Surface(x=x1_grid, y=x2_grid, z=yhat, opacity=0.5,colorscale='Gray')\n",
    "    )\n",
    "    if residuals:\n",
    "        for i in range(len(x1)):\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(x=[x1[i], x1[i]], y=[x2[i], x2[i]], z=[b0 + b1*x1[i] + b2*x2[i], y[i]], mode='lines', line=dict(color='black', width=2))\n",
    "            )\n",
    "    fig.update_layout(showlegend=False, scene_camera=dict(eye=dict(x=2.0, y=0.5, z=0.1)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec7ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6dc53",
   "metadata": {},
   "source": [
    "## Key Takeaways from Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f31",
   "metadata": {},
   "source": [
    "\n",
    "#### Tuesday: \n",
    "\n",
    "... insert your key takeaways here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69de7b",
   "metadata": {},
   "source": [
    "#### Thursday\n",
    "\n",
    "... insert your takeaway here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadbca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2f50d",
   "metadata": {},
   "source": [
    "# Regularization & Shrinking Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd014f40",
   "metadata": {},
   "source": [
    "Choosing `alpha` via:\n",
    "1. alpha for each covariate graph\n",
    "2. cross validation error comparing with alpha graph (shows bias variance tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d368fda",
   "metadata": {},
   "source": [
    "### Intuition for Ridge and LASSO\n",
    "\n",
    "* In the absence of $p_\\lambda(\\beta_1, \\beta_2, \\dots, \\beta_p)$ the objective is to minimize the residual sum of squares loss function, i.e., \n",
    "\n",
    "$$\n",
    "\\mathop{\\min} L(\\beta_0, \\beta_2, \\dots, \\beta_p)\n",
    "$$\n",
    "\n",
    "\n",
    "* After adding the penalty term, the objective can equivalently be written as\n",
    "\n",
    "$$\n",
    "\\mathop{\\min} L(\\beta_0, \\beta_2, \\dots, \\beta_p)\\\\ \\\\\n",
    "s.t. \\quad p(\\beta_1, \\dots, \\beta_p) \\leq t\n",
    "$$\n",
    "\n",
    "where the value of **$t$ is inversely related to $\\lambda$**\n",
    "- if $t$ is small then $\\lambda$ in $p_\\lambda(\\cdot)$ is large and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07326344",
   "metadata": {},
   "source": [
    "Consider the following example:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "Suppose the values $(\\hat\\beta_1, \\hat\\beta_2)$ which minimize the loss function are:\n",
    "\n",
    "$$\n",
    "(\\hat\\beta_1, \\hat\\beta_2) = (1, 1)\n",
    "$$\n",
    "\n",
    "The loss function \n",
    "\n",
    "$$\n",
    "L(\\beta_1, \\beta_2) = \\sum_{i=1}^n (y_i - \\beta_1x_{1i} - \\beta_2 x_{2i})^2\n",
    "$$\n",
    "\n",
    "define ellipsoidal regions in the $\\beta_1, \\beta_2$ plane with the minimum at $(\\hat\\beta_1, \\hat\\beta_2) = (1, 1)$.\n",
    "\n",
    "$$\n",
    "(\\beta_1^2 a) + (\\beta_2^2 c) + (\\beta_1 \\cdot \\beta_2 \\cdot d) + \\dots = 0\n",
    "$$\n",
    "\n",
    "This is a `conic` section equation, which is deternmined by actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9b46b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57deb6381b2e430da0ccf7661efd6fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.75, description='t', max=1.5, min=0.01, step=0.01), FloatSlider(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = (1, 1)\n",
    "\n",
    "@interact(t=(0.01, 1.5, 0.01), l1wt=(0, 1, 0.1))\n",
    "def plot(t, l1wt):\n",
    "    x1seq = np.linspace(-3, 3, 500)\n",
    "    x2seq = np.linspace(-3, 3, 500)\n",
    "    X1, X2 = np.meshgrid(x1seq, x2seq)\n",
    "    d = np.array([X1.flatten(), X2.flatten()]).T\n",
    "\n",
    "    z = [ l1wt * (np.abs(x[0]) + np.abs(x[1])) + (1-l1wt) * (x[0]**2 + x[1]**2) < t for x in d]\n",
    "    Z = np.array(z).reshape(X1.shape)\n",
    "\n",
    "    y = [(x[0]-b[0])**2 / 3 + (x[1] - b[1])**2 /0.5 + 1 * (x[0] - b[0]) * (x[1] - b[1]) for x in d]\n",
    "    Y = np.array(y).reshape(X1.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.axhline(0, color='black', lw=2)\n",
    "    ax.axvline(0, color='black', lw=2)\n",
    "    ax.contourf(X1, X2, Z, alpha=0.5)\n",
    "    # line contours of X1, X2, Y with colors representing the value of Y on each contour with magma theme\n",
    "    # reverse the color map\n",
    "    ax.contour(X1, X2, Y, levels=np.linspace(0, 2, 10), cmap='inferno_r', linestyles='dashed')\n",
    "    ax.set_xlabel('b1')\n",
    "    ax.set_ylabel('b2')\n",
    "    ax.set_title(f'Contour plot of $\\\\lambda$ = {l1wt: .3f} and $t$ = {t: .3f}')\n",
    "    ax.plot(b[0], b[1], 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0854a0c1",
   "metadata": {},
   "source": [
    "Dependending on the specific formulation, regularization is a projection that requires one to **move on the objective/loss surface while living in certain region**\n",
    "\n",
    "- For Ridge, it is a circle and we can find somewhere on the curve\n",
    "\n",
    "- For LASSO, it is a dimond and the only point it would take place would be **on the axis**, forcing all covaraitae but one to be zero -> giving much sparser covariate coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f002aa",
   "metadata": {},
   "source": [
    "### Desiderata\n",
    "\n",
    "A good penalty function should satisfy the following properties:\n",
    "\n",
    "1. ...\n",
    "2. ...\n",
    "3. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d038b",
   "metadata": {},
   "source": [
    "#### Competing objectives\n",
    "\n",
    "The regularization technique balances two competing objectives:\n",
    "\n",
    "1. ...\n",
    "2. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d23ab7",
   "metadata": {},
   "source": [
    "#### Penalty function: New\n",
    "\n",
    "This could be a useful penalty function because ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fb562",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a37685",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Into unsupervised, given variables $(X_1, X_2, \\dots, X_p)$, PCA produces a low-dimensional representation of the dataset, i.e.,\n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{observation } 1 &: \\quad (X_{1,1}, X_{2,1}, \\dots, X_{p,1}) \\quad \\longrightarrow \\quad (Z_{1,1}, Z_{2,1}) \\\\\n",
    "\\text{observation } 2 &: \\quad (X_{1,2}, X_{2,2}, \\dots, X_{p,2}) \\quad \\longrightarrow \\quad (Z_{1,2}, Z_{2,2}) \\\\\n",
    "&\\quad \\vdots \\hspace{4cm} \\vdots \\\\\n",
    "\\text{observation } n &: \\quad (X_{1,n}, X_{2,n}, \\dots, X_{p,n}) \\quad \\longrightarrow \\quad (Z_{1,n}, Z_{2,n})\n",
    "\\end{aligned}\n",
    "\n",
    "> #### Goal of PCA:\n",
    ">\n",
    "> **Input:**\n",
    ">\n",
    "> Variables $X_1, X_2, \\dots, X_p$\n",
    ">\n",
    "> **Output:**\n",
    ">\n",
    "> A new set of variables $Z_1, Z_2, \\dots, Z_q$ where $q \\ll p$\n",
    ">\n",
    "> **Constraints:**\n",
    ">\n",
    "> 1. $Z_1, Z_2, \\dots, Z_q$ are linear combinations of $X_1, X_2, \\dots, X_p$\n",
    "> 2. $\\text{Var}(Z_1, Z_2, \\dots, Z_q) \\approx \\text{Var}(X_1, X_2, \\dots, X_p)$ (we want variance to be the same)\n",
    "> 3. $Z_1, Z_2, \\dots, Z_q$ are **uncorrelated**\n",
    ">\n",
    "> Where $V = (v_1, v_2, ..., v_p)$ is factor loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0927c8a",
   "metadata": {},
   "source": [
    "## Procedure of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a10ac6",
   "metadata": {},
   "source": [
    "The first **principal component** $Z_1$ is the *normalized* linear combination of the features:\n",
    "\n",
    "$$\n",
    "Z_1 = v_{11} X_1 + v_{21} X_2 + \\dots + v_{p1} X_p\n",
    "$$\n",
    "\n",
    "such that:\n",
    "1. $Z_1$ has the **largest possible variance**\n",
    "2. The weights satisfy the **constraint of unit vector**: $\\sum_{j=1}^{p} v_{j1}^2 = 1$\n",
    "    - We want to avoid too trivial solution where the magnitude of some vector just makes the x xomponent directly zero, so we limit the vectors to a unit circle, they are all unit vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a27b7f",
   "metadata": {},
   "source": [
    "> #### Courant-Fisher-Weyl Min-Max Theorem (Paraphrased)\n",
    ">\n",
    "> Consider the optimization:\n",
    ">\n",
    "> $$\n",
    "> \\max v^T \\cdot \\text{cov}(X) \\cdot v\n",
    "> $$\n",
    ">\n",
    "> subject to:\n",
    ">\n",
    "> $$\n",
    "> v \\cdot v = 1\n",
    "> $$\n",
    ">\n",
    "> - **Max value** = Largest eigenvalue of $X$\n",
    "> - **Maximizer** $v^*$ = Eigenvector corresponding to the largest eigenvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f8596",
   "metadata": {},
   "source": [
    "The **second principal component** $Z_2$ is the _normalized_ linear combination of the features:\n",
    "\n",
    "$$\n",
    "Z_2 = v_{12}X_1 + v_{22}X_2 + \\dots + v_{p2}X_p\n",
    "$$\n",
    "\n",
    "such that:\n",
    "\n",
    "- $V_2 \\perp V_1$ (orthogonal to the first principal component)\n",
    "- $Z_2$ has the largest possible variance\n",
    "- $\\sum_{i=1}^{p} v_{p2}^2 = 1$ (normalization constraint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0255e2a",
   "metadata": {},
   "source": [
    "The **qth principal component** $Z_q$ is the _normalized_ linear combination of the features:\n",
    "\n",
    "$$\n",
    "Z_q = v_{1q}X_1 + v_{2q}X_2 + \\dots + v_{pq}X_p\n",
    "$$\n",
    "\n",
    "such that:\n",
    "\n",
    "- $Z_q$ has the largest possible variance\n",
    "- $V_q \\perp \\text{span}(V_1, V_2, \\dots, V_{q-1})$ (orthogonal to the previous principal components)\n",
    "- $\\sum_{i=1}^{p} v_{p2}^2 = 1$ (normalization constraint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf2c35",
   "metadata": {},
   "source": [
    "**Eigfenvectors are very useful as they are the direct solution to the optimization probelm that we care about, it links eigen decomposition/singular value deconposition to the optimization we want in PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1d320",
   "metadata": {},
   "source": [
    "PCA was namely originally trying to address multicolinearioty (think back in deep learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2054701",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55632b42",
   "metadata": {},
   "source": [
    "# Characteristic of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10715c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
