{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499b8cf",
   "metadata": {},
   "source": [
    "# Math 189 Week 8 Summary\n",
    "> NAME: $\\color{blue}{\\text{Kaiwen Bian}}$\n",
    "> \n",
    "> PID: $\\color{blue}{\\text{A17316568}}$\n",
    ">\n",
    "> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce0cf8",
   "metadata": {},
   "source": [
    "I certify that the following write-up is my own work, and have abided by the UCSD Academic Integrity Guidelines.\n",
    "\n",
    "- [x] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c41b1",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$%$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$%$\n",
    "$\\forcecommand{\\supp}{\\text{supp}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\forcecommand{\\var}{\\text{Var}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\ci}{\\text{CI}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec7ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bce66805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# pio.renderers.default='notebook'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Optional \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "matplotlib.rcParams['figure.figsize'] = 7, 7\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9052c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_X(X, ax, type='pmf', **kwargs):\n",
    "    ax.set_xlabel('Support')\n",
    "    ax.set_title(f'{X.dist.name}{X.args}')\n",
    "    \n",
    "    min_X, max_X = X.ppf((1e-3, 1-1e-3))\n",
    "    supp_X = np.linspace(min_X-1, max_X + 1, 200)\n",
    "    \n",
    "    if type == 'pmf':\n",
    "        supp_X = np.arange(min_X-1, max_X + 1)\n",
    "        ax.bar(supp_X, X.pmf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PMF')\n",
    "    elif type == 'pdf':\n",
    "        ax.plot(supp_X, X.pdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PDF')\n",
    "    elif type == 'cdf':\n",
    "        ax.plot(supp_X, X.cdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('CDF')\n",
    "    else:\n",
    "        raise ValueError('type must be pmf or cdf')\n",
    "\n",
    "def decision(pvalue, alpha):\n",
    "    if pvalue < alpha:\n",
    "        print(f'reject H0: pvalue={pvalue} < {alpha}')  \n",
    "    else: \n",
    "        print(f'fail to reject H0: pvalue={pvalue} ≥ {alpha}')\n",
    "\n",
    "def standardize(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "\n",
    "def make_data(errors):\n",
    "    n = len(errors)\n",
    "    x1 = np.linspace(0, 1, n)\n",
    "    x2 = np.random.rand(n)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'x1': x1, \n",
    "        'x2': x2, \n",
    "        'y': 2 + 3*x1 + 4*x2 + errors\n",
    "    })\n",
    "\n",
    "def plot_regression(data, fit, residuals=True):\n",
    "    b = fit.params\n",
    "    b0, b1, b2 = *b, *np.zeros(3 - len(b))\n",
    "    y, x1, x2 = data.y, data.x1, data.x2\n",
    "    fig = px.scatter_3d(x=x1, y=x2, z=y)\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis_title='X1',\n",
    "            yaxis_title='X2',\n",
    "            zaxis_title='Y'),\n",
    "            margin=dict(l=0, r=0, b=0, t=0\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    \n",
    "    x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "    yhat = b0 + (b1 * x1_grid) + (b2 * x2_grid)\n",
    "    fig.add_trace(\n",
    "        go.Surface(x=x1_grid, y=x2_grid, z=yhat, opacity=0.5,colorscale='Gray')\n",
    "    )\n",
    "    if residuals:\n",
    "        for i in range(len(x1)):\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(x=[x1[i], x1[i]], y=[x2[i], x2[i]], z=[b0 + b1*x1[i] + b2*x2[i], y[i]], mode='lines', line=dict(color='black', width=2))\n",
    "            )\n",
    "    fig.update_layout(showlegend=False, scene_camera=dict(eye=dict(x=2.0, y=0.5, z=0.1)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6dc53",
   "metadata": {},
   "source": [
    "## Key Takeaways from Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f31",
   "metadata": {},
   "source": [
    "\n",
    "#### Tuesday: \n",
    "\n",
    "... insert your key takeaways here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69de7b",
   "metadata": {},
   "source": [
    "#### Thursday\n",
    "\n",
    "... insert your takeaway here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadbca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915e324",
   "metadata": {},
   "source": [
    "# Rest of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a08f9",
   "metadata": {},
   "source": [
    "> #### Interpretation of coefficients\n",
    "\n",
    "The interprettaion of it comes from a log scale. Given the logistic regression model:\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "The partial derivative of the log-odds with respect to $ x_i $ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i} \\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_i\n",
    "$$\n",
    "\n",
    "This means that the coefficient $ \\beta_i $ is the expected change in the log-odds of the response variable for an infinitesimal change in $ x_i $, holding all other variables constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b5a0f",
   "metadata": {},
   "source": [
    "**log odds is not as easy to interpret**, we will look at another term to discuss about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287e5fd",
   "metadata": {},
   "source": [
    "#### Odds-Ratio\n",
    "\n",
    "If we want an interpretation on the odds-scale (which is more intuitive), we need to do a little more math.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Given two events $A$ and $B$, the odds-ratio of $A$ to $B$ is:\n",
    "\n",
    "$$\n",
    "\\text{odds-ratio}(A:B) = \\frac{\\text{odds}(A)}{\\text{odds}(B)} = \\frac{\\pr(A)/\\pr(A^c)}{\\pr(B)/\\pr(B^c)} = \\frac{\\pr(A)\\pr(B^c)}{\\pr(A^c)\\pr(B)}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Now, consider the following events:\n",
    "\n",
    "* $A = \\{y=1 \\mid x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i\\}$\n",
    "* $B = \\{y=1 \\mid x_1, x_2, \\dots, x_p \\text{ and } x_i = x_i + 1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f4f01",
   "metadata": {},
   "source": [
    "Now we can say that:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{odds}(A) &= \\text{odds}(y=1 | x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i)\\\\ \\\\ \n",
    "&= \\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i)\\\\ \\\\ \\\\ \\\\\n",
    "\\text{odds}(B) &= \\text{odds}(y=1 | x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i + 1)\\\\ \\\\ \n",
    "&= \\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i + \\beta_i)\\\\ \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{odds-ratio}(B:A) &= \\frac{\\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i + \\beta_i)}{\\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i)}\\\\ \\\\\n",
    "&= \\exp(\\beta_i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c396d7c",
   "metadata": {},
   "source": [
    "This leads to the following interpretation of the coefficient $\\beta_i$:\n",
    "\n",
    "$$\n",
    "\\exp(\\beta_i) = \\frac{\\text{odds}(y=1 \\mid x_i = x_i + 1)}{\\text{odds}(y=1 \\mid x_i = x_i)}\n",
    "$$\n",
    "\n",
    "i.e., $\\exp(\\beta_i)$ is the **relative change** in odds for **a one unit change** in $x_i$ holding all other variables constant.\n",
    "\n",
    "* $\\beta_i < 0$ implies that a **one unit increase** in $x_i$ **decreases** the odds of the response variable $y=1$.\n",
    "* $\\beta_i > 0$ implies that a **one unit increase** in $x_i$ **increases** the odds of the response variable $y=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbcec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "df = bank_marketing.data.features\n",
    "df['outcome'] = bank_marketing.data.targets['y'].transform(lambda x: 1 if x == 'yes' else 0)\n",
    "to_drop = ['contact', 'poutcome', 'pdays', 'pdays']\n",
    "df = df.drop(columns=to_drop)\n",
    "df = df.dropna()\n",
    "categorical_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month', 'day_of_week']\n",
    "\n",
    "for var in categorical_vars:\n",
    "    df[var] = df[var].astype('category')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = smf.logit('outcome ~ duration + balance + job + marital + default', data=df).fit()\n",
    "\n",
    "print(logistic_model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad6baf",
   "metadata": {},
   "source": [
    "> #### Logistic regression assumptions\n",
    "\n",
    "Given data $(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)$, the logistic regression model assumes that:\n",
    "\n",
    "- The response variable $y_i$ is a Bernoulli random variable with parameter $p(x_i)$, i.e.,\n",
    "  \n",
    "  $$\n",
    "  y | x_1, x_2, \\dots, x_p \\sim \\text{Ber}(p(x_1, x_2, \\dots, x_p))\n",
    "  $$\n",
    "\n",
    "- The function $p^{-1}(x)$ is a linear function of the predictor variables, i.e.,\n",
    "\n",
    "  $$\n",
    "  \\sigma^{-1}(p(x)) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "  $$\n",
    "\n",
    "This is the **key** assumption on the data for making inference.\n",
    "\n",
    "- This is the **inverse of the noraml distribution** CDF (whi it is called probid or logits in libraries)\n",
    "- This help us connect logistic regression to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate y | x from bernoulli\n",
    "\n",
    "sigma = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "p_inv = lambda x1, x2: 3 + 4 * x1 - 2 * x2\n",
    "\n",
    "x1 = np.random.normal(0, 1, 1000)\n",
    "x2 = np.random.normal(0, 1, 1000)\n",
    "\n",
    "p = sigma(p_inv(x1, x2))\n",
    "y = stats.bernoulli(p).rvs(1000)\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d12e6d",
   "metadata": {},
   "source": [
    "> #### Maximum likelihood to bernulli distribution\n",
    "**We are essentially trying to maximize the likelihood of our created distribution via logistic regression towards to true binomial distribution of the data (from binary cross entropy).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8157d28",
   "metadata": {},
   "source": [
    "Given the data $(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)$, the likelihood function is the following when data follows a Bernulli distribution:\n",
    "\n",
    "$$\n",
    "L(\\beta) = \\prod_{i=1}^{n} p(x_i)^{y_i} (1 - p(x_i))^{1 - y_i}\n",
    "$$\n",
    "\n",
    "\n",
    "The log-likelihood function is\n",
    "\n",
    "$$\n",
    "\\ell(\\beta) = \\sum_{i=1}^{n} y_i \\log(p(x_i)) + (1 - y_i) \\log(1 - p(x_i))\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{i=1}^{n} y_i \\log \\left( \\frac{p(x_i)}{1 - p(x_i)} \\right) + \\log(1 - p(x_i))\n",
    "$$\n",
    "\n",
    "This is the prcise **binary cross entropy** function that we would be using. It is the log likelihood function of MLE that you would get when asssuming that data comes from a bernulli distribution. For bernulli distribution data, we can do MLE with this objective\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Now, let's we can write logistic regression models using the sigmoid function:\n",
    "\n",
    "$$\n",
    "p(x_i) = \\mathbb{P}(y_i = 1 | x_i) = \\sigma(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2})\n",
    "$$\n",
    "\n",
    "Then the odds ratio is:\n",
    "\n",
    "$$\n",
    "\\frac{p(x_i)}{1 - p(x_i)} = \\text{odds}(y_i = 1 | x_i) = \\exp(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\log \\left( \\frac{p(x_i)}{1 - p(x_i)} \\right) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\n",
    "$$\n",
    "\n",
    "The log-likelihood function from MLE above is rewritten as the following when substituting in the logistic components\n",
    "\n",
    "$$\n",
    "\\ell(\\beta_0, \\beta_1, \\beta_2) = \\sum_{i=1}^{n} y_i \\left(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} \\right) + \\log(1 - \\sigma(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}))\n",
    "$$\n",
    "\n",
    "This is the binary cross-entropy loss when using logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e83473c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(b, df):\n",
    "    Bx = [b[0] + b[1] * x1 + b[2] * x2 for x1, x2 in zip(df.x1, df.x2)]\n",
    "    p = sigma(Bx)\n",
    "    ll = np.sum((Bx * y) + np.log(1 - sigma(Bx)))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "b0, b1, b2 = minimize(lambda b: -log_lik(b, df), [0, 0, 0]).x\n",
    "print(f' b0: {b0}\\n b1: {b1}\\n b2: {b2}')\n",
    "\n",
    "model = smf.logit('y ~ x1 + x2', data=df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42d865",
   "metadata": {},
   "source": [
    "> #### Diagnostics\n",
    "There are several ways to diagnose the logistic regression model fit. **Similar with linear regression**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505cc1c",
   "metadata": {},
   "source": [
    "The logistic regression model assumes that:\n",
    "\n",
    "$$\n",
    "y | x \\sim Ber(p(x))\n",
    "$$\n",
    "\n",
    "Therefore, in `statsmodels` the fitted values are given by:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\dots + \\hat{\\beta}_p x_p\n",
    "$$\n",
    "\n",
    "And the **predicted probabilities** are:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\hat{p}(x) = \\sigma(\\hat{\\beta}(x))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = model.fittedvalues\n",
    "\n",
    "b = model.params\n",
    "Bx = b['Intercept'] + b['x1'] * df.x1 + b['x2'] * df.x2\n",
    "\n",
    "np.testing.assert_allclose(fitted, Bx)\n",
    "\n",
    "np.column_stack(\n",
    "    [sigma(model.fittedvalues), model.predict(df)]\n",
    ")\n",
    "\n",
    "px = model.predict(df)\n",
    "px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca5780",
   "metadata": {},
   "source": [
    "The residual of logistic would be somewhat a little bit different:\n",
    "\n",
    "$$\n",
    "E(y|x) = p(x) \\quad\\quad \\text{and}\\quad\\quad Var(y|x) = p(x)(1 - p(x))\n",
    "$$\n",
    "\n",
    "The **standardized pearson residuals** are defined as:\n",
    "\n",
    "$$\n",
    "\\hat\\epsilon_i = \\frac{y_i - p(x_i)}{\\sqrt{p(x_i) \\times (1-p(x_i))}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model.resid_pearson\n",
    "plt.scatter(range(len(residuals)), residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686ac3f",
   "metadata": {},
   "source": [
    "> #### Fit of model\n",
    "For three of the most popular techniques for assessing model fit in logistic regression, the intuition is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c5b0a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate y | x from bernoulli\n",
    "\n",
    "sigma = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "p_inv = lambda x1, x2: 3 + 4 * x1 - 2 * x2 - 5 * x1 * x2\n",
    "\n",
    "x1 = np.random.normal(0, 1, 1000)\n",
    "x2 = np.random.normal(0, 1, 1000)\n",
    "\n",
    "p = sigma(p_inv(x1, x2))\n",
    "y = stats.bernoulli(p).rvs(1000)\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3768d5a2",
   "metadata": {},
   "source": [
    "**1. Heurostic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('y ~ x1 * x2', df).fit()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.scatterplot(data=df, x='x1', y='x2', hue='y', ax=ax[0], alpha=0.5)\n",
    "ax[0].set_xlim(-5, 5); ax[0].set_ylim(-5, 5); ax[0].set_title(\"Scatterplot\")\n",
    "\n",
    "x1_grid = np.linspace(-5, 5, 100)\n",
    "x2_grid = np.linspace(-5, 5, 100)\n",
    "\n",
    "X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "\n",
    "probs = model.predict(pd.DataFrame({'x1': X1.ravel(), 'x2': X2.ravel()}))\n",
    "P = probs.values.reshape(X1.shape)\n",
    "\n",
    "ax[1].set_title(\"Decision boundary\")\n",
    "cax = ax[1].contourf(X1, X2, P, cmap='viridis', levels=np.linspace(0, 1, 8), alpha=0.8)\n",
    "fig.colorbar(cax, ax=ax[1])\n",
    "sns.scatterplot(data=df, x='x1', y='x2', hue='y', ax=ax[1], alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f2fa7",
   "metadata": {},
   "source": [
    "**2. Confusion matrix**\n",
    "\n",
    "The confusion matrix is a table which shows the number of true positives, true negatives, false positives and false negatives.\n",
    "\n",
    "| $\\phantom{1}$ | Predicted 0 | Predicted 1 |\n",
    "|---|---|---|\n",
    "| Actual 0 | True Negative | False Positive |\n",
    "| Actual 1 | False Negative | True Positive |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d967bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = model.pred_table(threshold=0.1)\n",
    "true_pos = c_matrix[1, 1] / c_matrix[1].sum()\n",
    "true_neg = c_matrix[0, 0] / c_matrix[0].sum()\n",
    "false_pos = c_matrix[0, 1] / c_matrix[0].sum()\n",
    "false_neg = c_matrix[1, 0] / c_matrix[1].sum()\n",
    "print(f' True Positive rate: {true_pos: .3f}\\n True Negative rate: {true_neg: .3f}\\n False Positive rate: {false_pos: .3f}\\n False Negative rate: {false_neg: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96393c56",
   "metadata": {},
   "source": [
    "**3. ROC Curve**\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation of the trade-off between the **true positive TP rate and the false positive FP rate** for every possible cut-off value. It is a **graphical representation** of the confusing metrics.\n",
    "\n",
    "Then the Area Under the Curve (AUC) is a single scalar value that summarizes the performance of the model.\n",
    "\n",
    "- The ROC curve is always a monotnic increaing/flatten.\n",
    "\n",
    "- Straightline following slope is just a **random guessing** (equal TP and FP), area is maximzied when the curve is most away from the $x=y$ line.\n",
    "\n",
    "- Though doesn't tell you much interpretation of each of teh coeefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df.y, model.predict(df))\n",
    "indx = (0.1 - 5e-3 <= thresholds) * (thresholds <= 0.1 + 5e-3)\n",
    "tpr[indx], fpr[indx],  thresholds[indx]\n",
    "metrics.RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "print(f\"AOC is: {metrics.roc_auc_score(df.y, model.predict(df))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b89534",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cc0d6",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression\n",
    "If we try to fit an OLS model to categorical data (non binary), as like it is binary data, it would lead to inconsistent predictions.\n",
    "\n",
    "When the response variable $y$ has more than two levels, we can extend the logistic regression model to **multinomial logistic regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630714d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "iris = fetch_ucirepo(id=53) \n",
    "\n",
    "df = iris.data.features\n",
    "df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "\n",
    "df['y'] = iris.data.targets.astype('category')\n",
    "df['y'] = df['y'].astype('category')\n",
    "\n",
    "order = ['Iris-virginica', 'Iris-versicolor', 'Iris-setosa']\n",
    "df['y'] = df['y'].cat.reorder_categories(order, ordered=False)\n",
    "df['y_numeric'] = df['y'].cat.codes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72326620",
   "metadata": {},
   "source": [
    "The multinomial logistic regression model is a generalization of the logistic regression model to the case where the response variable can take on more than two values, assuming that:\n",
    "\n",
    "$$\n",
    "y | x \\sim \\text{Categorical}(\\pi(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34eeff1",
   "metadata": {},
   "source": [
    "Here we're going to assume that the parameters $ \\pi(x) $ are given by **bunch of seperate distribution**:\n",
    "\n",
    "$$\n",
    "\\pi(x) = (\\pi_1(x), \\pi_2(x), \\dots, \\pi_k(x))\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\pi_i(x) = \\mathbb{P}(y = i | x), \\quad \\text{for } i = 2,3,4, \\dots, k\n",
    "$$\n",
    "\n",
    "and the first parameter is given by:\n",
    "\n",
    "$$\n",
    "\\pi_1(x) = 1 - \\sum_{i=2}^{k} \\pi_i(x)\n",
    "$$\n",
    "\n",
    "Additionally,\n",
    "\n",
    "$$\n",
    "\\text{Ber}(p) = \\text{Categorical}(1 - p, p)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05c063",
   "metadata": {},
   "source": [
    "Since all of the $\\pi_i(x)$ are probabilities, we can use the logistic regression trick.\n",
    "\n",
    "- There's one **key difference**, the odds has different construction:\n",
    "\n",
    "> **Logistic regression**\n",
    "\n",
    "The odds for logistic regression is  \n",
    "\n",
    "$$\n",
    "\\text{odds}(\\{ y = 1 | x \\}) = \\frac{\\mathbb{P}(y = 1 | x)}{\\mathbb{P}(y = 0 | x)}\n",
    "$$  \n",
    "\n",
    "> **Multinomial logistic regression**s\n",
    "\n",
    "We need to **choose something as the base category**, make it **relative**. The odds looking at is different. The odds for multinomial logistic regression is  \n",
    "\n",
    "$$\n",
    "\\text{odds}(\\{ y = i | x \\}) = \\frac{\\mathbb{P}(y = i | x)}{\\mathbb{P}(y = 1 | x)}\n",
    "$$  \n",
    "\n",
    "The odds are always with reference to the **baseline** category. We need to manually impose to make it a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53fd06",
   "metadata": {},
   "source": [
    "Then we will just fit $k$ logistic model, you are comparing many with whatever you choose as the baseline category.\n",
    "\n",
    "$$\n",
    "\\log \\left( \\frac{\\pi_i(x)}{\\pi_1(x)} \\right) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_{ip} x_p, \\quad \\text{for } i = 2, 3, 4, \\dots, k\n",
    "$$\n",
    "\n",
    "Note the $\\beta_{ip}$ term. This is the key difference between the multinomial logistic regression model and the logistic regression model.\n",
    "\n",
    "> *Essentially, the multinomial logistic regression model fits* $(k - 1)$ *different logistic regression models, one for each category, with the first category as the reference category.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555b1e2",
   "metadata": {},
   "source": [
    "In `statsmodels` you can fit a multinomial logistic regression model using the `MNLogit` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model = smf.mnlogit('y_numeric ~ sepal_length + sepal_width + petal_length + petal_width', data=df).fit()\n",
    "print(mnl_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037c339",
   "metadata": {},
   "source": [
    "> #### Interpretation of the coefficients\n",
    "\n",
    "Consider the following events $A$ and $B$:\n",
    "\n",
    "- $ A = \\{ y = i \\mid x_1, x_2, \\dots, x_p, \\text{ and } x_j = x_j \\} $\n",
    "- $ B = \\{ y = i \\mid x_1, x_2, \\dots, x_p, \\text{ and } x_j = x_j + 1 \\} $\n",
    "\n",
    "If we were to fit a multinomial logistic regression model to the data, the interpretation of the coefficients would be:\n",
    "\n",
    "$$\n",
    "\\text{odds-ratio}(B : A) = \\exp(\\beta_{ij})\n",
    "$$\n",
    "\n",
    "Going to the $i$ -th table and look at the $j$ -th row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011684d",
   "metadata": {},
   "source": [
    "> #### Marginal Effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f879b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnl_model.get_margeff(method='dydx').summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15473cf",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe5aee",
   "metadata": {},
   "source": [
    "# Variable Selection: Balancing\n",
    "\n",
    "How can we select the most **optimal subset** of these variables. Usually ANOVA allow us to do this by asking \"is the big model truely adding things that is valuable when looking at varaince\". Now w  are doing it at a much more bigger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3b7b1",
   "metadata": {},
   "source": [
    "The objective of variable selection is to identify the most important predictors, and include them in the final regression model. There are three main approaches to variable selection:\n",
    "\n",
    "1. **All possible subsets**: Fit all possible models and select the best one based on some criterion.\n",
    "    - However, the number of  combinations grows exponentially with the number of covariate you have $2^p$,not scalable\n",
    "2. **Stepwise selection**: Start with the full or the null model and iteratively add or remove predictors based on some criterion.\n",
    "    - Iteratively **prune** or **grow** the model. Greedy search happenening on covariate space.\n",
    "3. **Shrinkage methods**: Use a penalty to shrink the coefficients of the less important predictors to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0495a82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Selection Criterion\n",
    "\n",
    "**Need trade-off between model fit and model complexity, old clasic problem in ML. This criterion decides teh final model fitted**\n",
    "\n",
    "The selection criterion needs to take into account the trade-off between the goodness of fit and the complexity of the model.\n",
    "\n",
    "- As you include more predictors, the model will fit the data better. **The model fit cannot get worse**.\n",
    "- However, as you include more predictors, the model becomes more complex and may not generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec9bd1",
   "metadata": {},
   "source": [
    "We can do it more systematically with partial model and full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e270466",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = 100, 75\n",
    "np.random.seed(2025)\n",
    "\n",
    "true_p = np.random.choice(range(p), replace=False, size=5)\n",
    "true_b = np.array([2,3,4,5,6])\n",
    "\n",
    "x = np.random.randn(n, p)\n",
    "toy_df = pd.DataFrame(x, columns=[f'x{i}' for i in range(p)])\n",
    "toy_df[\"y\"] = x[:, true_p] @ true_b + np.random.randn(n)\n",
    "\n",
    "df = toy_df\n",
    "\n",
    "true_x = set(df.columns[true_p])\n",
    "print(f'true_x: {true_x}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d40ea6",
   "metadata": {},
   "source": [
    "> Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ecf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = 'y'\n",
    "all_variables = df.columns.drop(response)\n",
    "full_model_formula = f'{response} ~ {\" + \".join(all_variables)}'\n",
    "full_model_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee25d48",
   "metadata": {},
   "source": [
    "> True model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e226162",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model_formula = 'y ~ ' + ' + '.join(df.columns[true_p])\n",
    "true_model_formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b568a",
   "metadata": {},
   "source": [
    "Let's look at the full model, which includes all the predictors vs. the true model which only includes the variables under the true_p index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = smf.ols(full_model_formula, data=df).fit()\n",
    "true_model = smf.ols(true_model_formula, data=df).fit()\n",
    "\n",
    "print(f'full model R2: {full_model.rsquared}')\n",
    "print(f'true model R2: {true_model.rsquared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb47da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'True model\\n {true_model.summary().tables[0]}\\n\\n')\n",
    "print(f'Full model\\n {full_model.summary().tables[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc43a20",
   "metadata": {},
   "source": [
    "How do we choose between them, we have **three different** type of sleection criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6553fc3",
   "metadata": {},
   "source": [
    "### Adjusted R-squared\n",
    "\n",
    "The adjusted R-squared is a modified version of R-squared that has been adjusted for the number of predictors in the model. The adjusted R-squared increases only if the new term **substantially improves** the model more than just by random chance.\n",
    "\n",
    "In particular, recall that the **vanilla R-squared** is calculated as:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}\n",
    "$$\n",
    "\n",
    "where $SS_{\\text{res}}$ is the sum of squares of the residuals and $SS_{\\text{tot}}$ is the total sum of squares. Then the **adjusted R-squared** is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\frac{n - 1}{n - p - 1} (1 - R^2)\n",
    "$$\n",
    "\n",
    "where $n$ is the number of observations and $p$ is the number of predictors.\n",
    "\n",
    "**Larger $R^2$, better model fit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10790f",
   "metadata": {},
   "source": [
    "Observe that:\n",
    "\n",
    "* The adjusted R-squared will always be less than or equal to the R-squared.\n",
    "\n",
    "* If $p \\mapsto p+1$ but the R-squared of the new model stays the same\n",
    "    * Then the adjusted R-squared will decrease\n",
    "* If $p \\mapsto p+1$ and the R-squared of the new model increases substantially\n",
    "    * Then the adjusted R-squared will also increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fac10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a67d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_formula = 'y ~ 1 + x0 + x1'\n",
    "simple_model = smf.ols(simple_model_formula, data=df).fit()\n",
    "\n",
    "print(f'Simple model R2: {simple_model.rsquared}\\t Adjusted R2: {simple_model.rsquared_adj}')\n",
    "print(f'True model R2: {true_model.rsquared}\\t Adjusted R2: {true_model.rsquared_adj}')\n",
    "print(f'Full model R2: {full_model.rsquared}\\t Adjusted R2: {full_model.rsquared_adj}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model\n",
    "model_p = len(model.params) - 1\n",
    "adjr2 = 1 - (1 - model.rsquared) * (n - 1) / (n - model_p - 1)\n",
    "print(f'Adjusted R2: {adjr2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5741f23",
   "metadata": {},
   "source": [
    "Drawbacks of the adjusted R-squared:\n",
    "\n",
    "* It is not a good measure of the **goodness of fit** of the model\n",
    "* There is no good Adjusted R-squared metric for logistic and multinomial regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36946e",
   "metadata": {},
   "source": [
    "### Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)\n",
    "\n",
    "The AIC and BIC are measures of **the goodness of fit** of a model, adjusted for the number of predictors. They are both based on the **(log-)likelihood** of the model and the number of predictors.\n",
    "\n",
    "Remember the log-likelihood of the model is given by\n",
    "\n",
    "$$\n",
    "\\ell(\\beta) = \\sum_{i=1}^{n} \\log f(y_i | x_i, \\beta)\n",
    "$$\n",
    "\n",
    "where $f(y_i | x_i, \\beta)$ is the probability density function of the response variable given the predictors and the coefficients.\n",
    "\n",
    "The **AIC** is defined as\n",
    "\n",
    "$$\n",
    "AIC = -2\\ell(\\beta) + 2p\n",
    "$$\n",
    "\n",
    "and the **BIC** is defined as\n",
    "\n",
    "$$\n",
    "BIC = -2\\ell(\\beta) + p \\log n\n",
    "$$\n",
    "\n",
    "The key idea is that:\n",
    "- AIC: Penalizes model complexity with a constant $2p$, making it more lenient for adding predictors.\n",
    "- BIC: Uses a stronger penalty $p \\log(n)$, making it more conservative, especially with larger datasets.\n",
    "\n",
    "**Smaller AIC and BIC resembles better model fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8930d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Simple model AIC: {simple_model.aic} \\t BIC: {simple_model.bic}')\n",
    "print(f'True model AIC: {true_model.aic} \\t BIC: {true_model.bic}')\n",
    "print(f'Full model AIC: {full_model.aic} \\t BIC: {full_model.bic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model\n",
    "model_p = len(model.params)\n",
    "aic = -2 * model.llf + 2 * model_p\n",
    "bic = -2 * model.llf + np.log(n) * model_p\n",
    "print(f'AIC: {aic} \\t BIC: {bic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f5928",
   "metadata": {},
   "source": [
    "### Cross Validation Error\n",
    "\n",
    "The cross-validation error (also known as the test error or the out-of-sample error) is another metric for evaluating a model’s predictive power. It is based on the average error of the model on new data it didn’t have access to during the model fitting process.\n",
    "\n",
    "> 1. **Split the data into:**\n",
    ">    - a training set $y_{\\text{train}}, X_{\\text{train}}$ **and**\n",
    ">    - a test set $y_{\\text{test}}, X_{\\text{test}}$\n",
    "> \n",
    "> 2. **Fit the model on the training set and obtain** $\\hat{\\beta}_{\\text{train}}$\n",
    "> \n",
    "> 3. **Compute the fit of the model on the test set:**\n",
    "> \n",
    ">    $$\n",
    ">    \\hat{y}_{\\text{test}} = f(\\hat{\\beta}_{\\text{train}}, X_{\\text{test}})\n",
    ">    $$\n",
    "> \n",
    "> 4. **Compute the error of the model on the test set:**\n",
    "> \n",
    ">    $$\n",
    ">    || y_{\\text{test}} - \\hat{y}_{\\text{test}} ||\n",
    ">    $$\n",
    "\n",
    "This is really powerful because we can use this for any model! Does not make assumptions that we need to check like for the previous two models (assume mle of some sort of distribution). However, we  can not make **Inferences** and ties back to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'simple model formula: {simple_model_formula}')\n",
    "print(f'true model formula: {true_model_formula}')\n",
    "print(f'full model formula: {full_model_formula}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.25, random_state = 1)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fc6a0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_error(formula, train, test):\n",
    "    model = smf.ols(formula, data=train).fit()\n",
    "    yhat_test = model.predict(test)\n",
    "    error = np.sum((test['y'] - yhat_test) ** 2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7646d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Simple model: {cv_error(simple_model_formula, train, test)}')\n",
    "print(f'True model: {cv_error(true_model_formula, train, test)}')\n",
    "print(f'Full model: {cv_error(full_model_formula, train, test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88541134",
   "metadata": {},
   "source": [
    "* Advantages of cross-validation:\n",
    "    1. It can be used for any sort of model, i.e., you don't need to know how to compute the likelihood of the model\n",
    "    2. It is a good measure of the model's predictive power\n",
    "\n",
    "* Disadvantages of cross-validation:\n",
    "    1. It is computationally expensive\n",
    "    2. It is not a measure of the model's **goodness of fit**!!\n",
    "        * i.e., You can have two models with the same cross-validation error but one is a better fit than the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e1586",
   "metadata": {},
   "source": [
    "## Stepwise Selection\n",
    "\n",
    "Now that we have a selection criterion, let’s call it\n",
    "\n",
    "$$\n",
    "C(\\{x_1, x_2, \\dots, x_p\\})\n",
    "$$\n",
    "\n",
    "we can use this criterion to select the best model from all possible models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd8a78",
   "metadata": {},
   "source": [
    "### Forward Selection\n",
    "\n",
    "The forward selection algorithm starts with the **null model**\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + e\n",
    "$$\n",
    "\n",
    "and iteratively **adds** the predictor that most improves the model according to the selection criterion.\n",
    "\n",
    "That is, suppose we have variables $(x_{i_1}, x_{i_2}, \\dots, x_{i_k})$ in the model already. Then we **add** the predictor $x_j$ for $j \\notin \\{i_1, i_2, \\dots, i_k\\}$ that minimizes the criterion\n",
    "\n",
    "$$\n",
    "\\min_{j \\notin \\{i_1, i_2, \\dots, i_k\\}} C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\} \\cup x_j)\n",
    "$$\n",
    "\n",
    "Terminate if\n",
    "\n",
    "$$\n",
    "\\min_{j \\notin \\{i_1, i_2, \\dots, i_k\\}} C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\} \\cup x_j) > C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e74913",
   "metadata": {},
   "source": [
    "### Backward Selection\n",
    "\n",
    "The backward selection algorithm starts with the **full model**\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + e\n",
    "$$\n",
    "\n",
    "and iteratively **removes** predictors that least contribute to the model according to the selection criterion.\n",
    "\n",
    "That is, suppose we have variables $(x_{i_1}, x_{i_2}, \\dots, x_{i_k})$ in the model already. Then we **remove** the predictor $x_j$ for $j \\in \\{i_1, i_2, \\dots, i_k\\}$ which minimizes the criterion\n",
    "\n",
    "$$\n",
    "\\min_{j \\in \\{i_1, i_2, \\dots, i_k\\}} C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\} \\setminus x_j)\n",
    "$$\n",
    "\n",
    "Terminate if\n",
    "\n",
    "$$\n",
    "\\min_{j \\in \\{i_1, i_2, \\dots, i_k\\}} C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\} \\setminus x_j) > C(\\{x_{i_1}, x_{i_2}, \\dots, x_{i_k}\\})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb026ee",
   "metadata": {},
   "source": [
    "### Mixed Selection\n",
    "\n",
    "The mixed selection algorithm does a combination of forward and backward selection. It starts with the null model and iteratively **adds** _and/or_ **removes** predictors according to the selection criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca4660",
   "metadata": {},
   "source": [
    "**NOTICE that the two method does not neccessarily give you the same model. It gives you solution along the optimal path but not the optimal solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5c26e",
   "metadata": {},
   "source": [
    "We can write a simple function to do forward/backward selection using the `statsmodels` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = lambda formula, df: smf.ols(formula, data=df).fit().bic\n",
    "criterion(true_model_formula, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "57833364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(df, selected_columns, columns, criterion, response='y'):\n",
    "    best_criterion = np.inf\n",
    "    best_column = None\n",
    "    for column in columns - selected_columns:\n",
    "        new_columns = selected_columns.union({column})\n",
    "        formula = f'{response} ~ {\" + \".join(new_columns)}'\n",
    "        current_criterion = criterion(formula, df)\n",
    "        if current_criterion < best_criterion:\n",
    "            best_criterion = current_criterion\n",
    "            best_column = column\n",
    "    return selected_columns.union({best_column}), best_criterion\n",
    "\n",
    "def forward(df, criterion, response='y'):\n",
    "    selected_columns = set()\n",
    "    columns = set(df.columns.drop(response))\n",
    "    best_criterion = np.inf\n",
    "    while len(selected_columns) < len(columns):\n",
    "        potential_columns, current_criterion = add(df, selected_columns, columns, criterion, response)\n",
    "        if current_criterion > best_criterion:\n",
    "            break\n",
    "        else:\n",
    "            selected_columns = potential_columns\n",
    "            best_criterion = current_criterion\n",
    "            print(f'Criterion: {best_criterion}')\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_adj_criterion = lambda formula, df: -smf.ols(formula, data=df).fit().rsquared_adj\n",
    "bic_criterion = lambda formula, df: smf.ols(formula, data=df).fit().bic\n",
    "aic_criterion = lambda formula, df: smf.ols(formula, data=df).fit().aic\n",
    "\n",
    "forward_vars_aic = forward(df, aic_criterion, response='y')\n",
    "forward_vars_bic = forward(df, bic_criterion, response='y')\n",
    "forward_vars_r2 = forward(df, r2_adj_criterion, response='y')\n",
    "\n",
    "print(f'forward_vars_aic: {forward_vars_aic}')\n",
    "print(f'forward_vars_bic: {forward_vars_bic}')\n",
    "print(f'forward_vars_r2: {forward_vars_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_vars_bic, true_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_formula = f'y ~ {\" + \".join(forward_vars_bic)}'\n",
    "forward_model = smf.ols(forward_formula, data=df).fit()\n",
    "print(forward_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24bfb3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56041c0",
   "metadata": {},
   "source": [
    "## Another Perspective: Regularization / Shrinkage Methods\n",
    "\n",
    "Looking from another perspective, we try to deal with tradeoffs as well through the scope of regularization. We look at regularziation from **machine learning and optimization's perspective** before, let's look at it from a **statistical perspective now**.\n",
    "\n",
    "<br>\n",
    "\n",
    "* Regularization / Shrinkage methods are a class of methods that use a **penalty** to shrink **the coefficients of the less important predictors** to zero. \n",
    "\n",
    "* It achieves a similar objective to stepwise selection, but uses a slightly different strategy. \n",
    "\n",
    "\n",
    "To see this, first let's look at the objective function of the **standard regression** task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91a11a",
   "metadata": {},
   "source": [
    "> #### Standard Regression\n",
    "\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\n",
    "$$\n",
    "\n",
    "Recall that the **least-squares loss** selects the model with the smallest residual standard error, i.e., \n",
    "\n",
    "$$\n",
    "L(\\beta_0, \\beta_2, \\dots, \\beta_p) = SS_{Res} = \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_{1, i} - \\dots \\beta_p x_{p, i})^2\n",
    "$$\n",
    "\n",
    "\n",
    "The solution to this problem is denoted as follows:\n",
    "\n",
    "$$\n",
    "(\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2, \\dots, \\hat\\beta_p) = \\mathop{\\arg\\min}\\limits_{\\beta_1 \\dots \\beta_p} L(\\beta_0, \\beta_2, \\dots, \\beta_p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e916b",
   "metadata": {},
   "source": [
    "**We will then look at regu,larizor from a very statistical perspective!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5993fe",
   "metadata": {},
   "source": [
    "> #### Regularized Regression\n",
    "\n",
    "If we want to select only a subset of these variables in our final model, we can include a penalty term \n",
    "$$p_\\lambda(\\beta_1, \\dots, \\beta_p)$$ \n",
    "\n",
    "which **favours solutions which select smaller subsets of the variables.** In this setting, the objective function becomes\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "L_\\lambda(\\beta_0, \\beta_1, \\dots, \\beta_p) = L(\\beta_0, \\beta_2, \\dots, \\beta_p) + p_\\lambda(\\beta_1, \\dots, \\beta_p)\n",
    "}\n",
    "$$\n",
    "\n",
    "* Here $\\lambda$ is a user-defined parameter that controls the strength of the penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324132f9",
   "metadata": {},
   "source": [
    "> #### What do we want an ideal penalty function to do?\n",
    "\n",
    "\n",
    "1. We want $p_\\lambda(\\beta_1, \\beta_2, \\dots, \\beta_p)$ to be be **large** when too many predictors are included in the model. \n",
    "\n",
    "2. We want $p_\\lambda(\\beta_1, \\beta_2, \\dots, \\beta_p)$ to be **small** when only a few predictors are included in the model.\n",
    "\n",
    "3. Ideally, we want $p_\\lambda(\\beta_1, \\beta_2, \\dots, \\beta_p)$ to be **zero** when only the true predictors are included in the model.\n",
    "\n",
    "Unfortunately, this ideal is never achieved in practice! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdbe22",
   "metadata": {},
   "source": [
    "> #### The regularization trade-off\n",
    "\n",
    "The final solution to the regularized regression problem is denoted as follows:\n",
    "\n",
    "$$\n",
    "(\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2, \\dots, \\hat\\beta_p) = \\mathop{\\arg\\min}\\limits_{\\beta_1 \\dots \\beta_p} L(\\beta_0, \\beta_2, \\dots, \\beta_p) + p_\\lambda(\\beta_1, \\dots, \\beta_p)\n",
    "$$\n",
    "\n",
    "The solution to this problem is a trade-off between:\n",
    "\n",
    "* the **model fit** since we are minimizing $L(\\beta_0, \\beta_2, \\dots, \\beta_p)$\n",
    "* the **complexity of the model** since we are also minimizing $p_\\lambda(\\beta_1, \\dots, \\beta_p)$\n",
    "\n",
    "\n",
    "Observations:\n",
    "* If we only focus on $L(\\beta_0, \\beta_2, \\dots, \\beta_p)$, we will select too many variables.\n",
    "* If we only focus on $p_\\lambda(\\beta_1, \\dots, \\beta_p)$, we will end up selecting no predictors at all!\n",
    "* So the parameter $\\lambda$ controls the trade-off between the two objectives.\n",
    "\n",
    "**If you just choos the regularizer, you essentially just choose the null soluton picking no predictors at all**. We will look at a few ways of doing this loss in the following methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0236b5",
   "metadata": {},
   "source": [
    "> #### 1. The Ridge Penalty\n",
    "\n",
    "The ridge penalty is defined as\n",
    "\n",
    "$$\n",
    "p_\\lambda(\\beta_1, \\dots, \\beta_p) = \\lambda ||{\\betav}||^2 =  \\lambda \\sum_{j=1}^p \\beta_j^2\n",
    "$$\n",
    "\n",
    "The ridge penalty is also known as the $L_2$ penalty. It favours solutions where all the coefficients are small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da887d44",
   "metadata": {},
   "source": [
    "> #### 2. The Lasso Penalty\n",
    "\n",
    "The LASSO (Least Angle Shrinkage and Selection Operator) penalty is defined as\n",
    "\n",
    "$$\n",
    "p_\\lambda(\\beta_1, \\dots, \\beta_p) = \\lambda ||{\\betav}||_1 =  \\lambda \\sum_{j=1}^p |\\beta_j|\n",
    "$$\n",
    "\n",
    "The LASSO penalty is also known as the $L_1$ penalty. It favours solutions where many of the coefficients are zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79840bd4",
   "metadata": {},
   "source": [
    "> #### 3. The Elastic Net Penalty\n",
    "\n",
    "The elastic net penalty is a combination of the ridge and lasso penalties. It is defined as\n",
    "\n",
    "$$\n",
    "p_\\lambda(\\beta_1, \\dots, \\beta_p) = \\lambda \\Big( \\gamma ||{\\betav}||_1 + (1-\\gamma) ||{\\betav}||^2 \\Big)\n",
    "$$\n",
    "\n",
    "where $\\gamma$ controls how much of the penalty is due to the lasso penalty and $(1-\\gamma)$ controls how much of the penalty is due to the ridge penalty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311de91",
   "metadata": {},
   "source": [
    "We will look at an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04964c93",
   "metadata": {},
   "source": [
    "**Consider the Boston housing data:**\n",
    "\n",
    "\n",
    "The original data are 506 observations on 14 variables, medv being the target variable:\n",
    "\n",
    "* `crim` per capita crime rate by town\n",
    "* `zn` proportion of residential land zoned for lots over 25,000 sq.ft\n",
    "* `indus` proportion of non-retail business acres per town\n",
    "* `chas` Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "* `nox` nitric oxides concentration (parts per 10 million)\n",
    "* `rm` average number of rooms per dwelling\n",
    "* `age` proportion of owner-occupied units built prior to 1940\n",
    "* `dis` weighted distances to five Boston employment centres\n",
    "* `rad` index of accessibility to radial highways\n",
    "* `tax` full-value property-tax rate per USD 10,000\n",
    "* `ptratio` pupil-teacher ratio by town\n",
    "* ~`b` 1000(B - 0.63)^2 where B is the proportion of black residents by town~\n",
    "* `lstat` percentage of lower status of the population\n",
    "* `medv` median value of owner-occupied homes in USD 1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef963f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/MASS/Boston.csv\"\n",
    "boston = pd.read_csv(url)\n",
    "df = boston\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = boston\n",
    "response = 'medv'\n",
    "full_model_formula = f\"{response} ~ {'+'.join(df.columns.drop(response))}\"\n",
    "\n",
    "l1wt = 1.0\n",
    "alphas = np.linspace(1e-3, 0.5, 200)\n",
    "elastic_coefs = []\n",
    "for alpha in alphas:\n",
    "    elastic_fit = smf.ols(full_model_formula, data=df).\\\n",
    "                fit_regularized(method='elastic_net', alpha=alpha, L1_wt=l1wt)\n",
    "    elastic_coefs.append(elastic_fit.params[1:])\n",
    "\n",
    "# Dataframe of coefficients\n",
    "elastic_coefs = pd.DataFrame(elastic_coefs, index=alphas)\n",
    "elastic_coefs\n",
    "\n",
    "# plot each coefficient\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "for column in elastic_coefs.columns:\n",
    "    ax.plot(alphas, elastic_coefs[column], label=column)\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be57346",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fit = elastic_fit = smf.ols(full_model_formula, data=df).\\\n",
    "                fit_regularized(method='elastic_net', alpha=0.5, L1_wt=1.0)\n",
    "\n",
    "print(final_fit.params[final_fit.params > 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = final_fit.params[final_fit.params != 0].index[2:]\n",
    "\n",
    "print(smf.ols( f'{response} ~ {\"+\".join(final_params)}', df).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2054701",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
