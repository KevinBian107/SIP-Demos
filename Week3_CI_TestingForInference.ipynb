{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499b8cf",
   "metadata": {},
   "source": [
    "# Math 189 Week 3 Summary\n",
    "> NAME: $\\color{blue}{\\text{Kaiwen Bian}}$\n",
    "> \n",
    "> PID: $\\color{blue}{\\text{A17316568}}$\n",
    ">\n",
    "> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce0cf8",
   "metadata": {},
   "source": [
    "I certify that the following write-up is my own work, and have abided by the UCSD Academic Integrity Guidelines.\n",
    "\n",
    "- [x] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c41b1",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$%$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$%$\n",
    "$\\forcecommand{\\supp}{\\text{supp}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\forcecommand{\\var}{\\text{Var}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\ci}{\\text{CI}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0120db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "\n",
    "# Optional \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cace5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def plot_X(X, ax, type='pmf', **kwargs):\n",
    "    ax.set_xlabel('Support')\n",
    "    ax.set_title(f'{X.dist.name}{X.args}')\n",
    "    \n",
    "    min_X, max_X = X.ppf((1e-3, 1-1e-3))\n",
    "    supp_X = np.linspace(min_X-1, max_X + 1, 200)\n",
    "    \n",
    "    if type == 'pmf':\n",
    "        supp_X = np.arange(min_X-1, max_X + 1)\n",
    "        ax.bar(supp_X, X.pmf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PMF')\n",
    "    elif type == 'pdf':\n",
    "        ax.plot(supp_X, X.pdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('PDF')\n",
    "    elif type == 'cdf':\n",
    "        ax.plot(supp_X, X.cdf(supp_X), **kwargs)\n",
    "        ax.set_ylabel('CDF')\n",
    "    else:\n",
    "        raise ValueError('type must be pmf, pdf, or cdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6dc53",
   "metadata": {},
   "source": [
    "# Key Takeaways from Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f31",
   "metadata": {},
   "source": [
    "### Tuesday: \n",
    "\n",
    "We discuessed some crucial property of probability such as LLN and CLT first. Afterwards, we mainly discussed about the the key ideas into confidence intervals and coverage probability. Then we dived into different forms of using confidence intervals and how ceratin assumptions that we use may not be a good approximation (i.e., need to use Welch-Satterthwaite Approximation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69de7b",
   "metadata": {},
   "source": [
    "### Thursday：\n",
    "\n",
    "We started with teh discussion of the anatomy of hypothesis testing, what are the components, what are the assumptions, etc. We then extended the conversation to the crucial concept of $p$-value and used many real-life data for testing hypothesis as examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9387",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952b8b8",
   "metadata": {},
   "source": [
    "# Crucial Principals of Probability in Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09dda7",
   "metadata": {},
   "source": [
    "Suppose $X_1, X_2, \\dots, X_n$ are $n$ iid samples from a distribution with mean $\\E(X) = M$ and variance $\\text{var}(X) = V$.\n",
    "\n",
    "Let $$\\Xbar = \\frac{1}{n} \\sum_{i=1}^n X_i$$ be the sample mean and $$S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\Xbar)^2$$ be the sample variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0639d4",
   "metadata": {},
   "source": [
    "## Law of Large Numbers\n",
    "\n",
    "* The **Law of Large Numbers** says that as the number of observations increases, the average of the observed values gets closer and closer to the expected value.\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n X_i \\rightarrow \\mathbb{E}(X) \\quad \\text{as } n \\rightarrow \\infty\n",
    "$$\n",
    "\n",
    "* This holds no matter what teh underlaying distribution is. As long as we have enough samples, it will always converge to theoritical distributions that governs the **data generation process**.\n",
    "\n",
    "* True expectation variation of the observation is decreasing, it facilitates LLN, which is stated in CLM, sttaing about as N increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Law of large numbers for N(mu, sigma^2)\n",
    "\n",
    "@interact(mu=(-3.0, 3.0, 0.5), num_trials=[10, 50, 100, 1000, 10000], sigma=(0.1, 10.0))\n",
    "def norm_lln(num_trials=10, mu=0.0, sigma=1.0):\n",
    "    rs = np.random.RandomState(np.random.randint(1,10))\n",
    "    X = stats.norm(mu, sigma)\n",
    "    Xs = X.rvs(num_trials, rs)\n",
    "    average_X = np.cumsum(Xs) / np.arange(1, num_trials + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.set_ylim([-3, 3])\n",
    "\n",
    "    ax.plot(range(1, num_trials + 1), average_X)\n",
    "    ax.axhline(y=mu, color='red', linestyle='--')\n",
    "    ax.set_xlabel('Number of trials')\n",
    "    ax.set_ylabel('Average')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017485fa",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "* The **Central Limit Theorem** says that as the number of observations increases, the **_distribution_** of the observed values gets closer and closer to the normal distribution.\n",
    "\n",
    "$$\n",
    "\\frac{\\overline{X} - \\mathbb{E}(X)}{\\sqrt{\\text{Var}(\\overline{X})}} \\Longrightarrow N(0,1) \\quad \\text{as } n \\rightarrow \\infty\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = stats.norm(0, 2)\n",
    "# X = stats.chi2(20)\n",
    "X = stats.uniform(-10, 10)\n",
    "# X = stats.expon(10)\n",
    "\n",
    "@interact(n=(50, 2000, 50))\n",
    "def clt(n=50):\n",
    "    Xn = np.array([(X.rvs(n).mean() - X.mean()) / (X.std() / np.sqrt(n)) for _ in range(n)])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    sns.histplot(Xn, bins=50, stat='density', ax=axs[0])\n",
    "    xlim = axs[0].get_xlim()\n",
    "    xs = np.linspace(*xlim, 100)\n",
    "    axs[0].plot(xs, stats.norm.pdf(xs), color='red', linestyle='--')\n",
    "    axs[0].set_title(f'{n} samples from {X.dist.name}{X.args}')\n",
    "\n",
    "    ecdf = lambda x: np.sum(Xn < x) / n\n",
    "    axs[1].plot(xs, stats.norm.cdf(xs), color='red', linestyle='--')\n",
    "    axs[1].plot(xs, [ecdf(x) for x in xs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b3b0e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_toss(size=1):\n",
    "    return np.random.choice(['H', 'T'], size=size)\n",
    "\n",
    "## Law of large numbers\n",
    "X = lambda num_coins: np.unique(coin_toss(num_coins), return_counts=True)[1][0]\n",
    "Y = lambda num_coins: 1 if np.unique(coin_toss(num_coins), return_counts=True)[1][0] == 2 else 0\n",
    "\n",
    "# Number of trials and coin tosses per trial\n",
    "num_trials, num_coins = 100, 4\n",
    "\n",
    "@interact(num_trials=[10, 100, 500, 1000], num_coins=fixed(4))\n",
    "def many_trials(num_trials, num_coins):\n",
    "    # Number of heads per trial\n",
    "    Xs = [X(num_coins) for _ in range(num_trials)]\n",
    "    Ys = [Y(num_coins) for _ in range(num_trials)]\n",
    "\n",
    "    # plot num_trials vs average(num_heads)\n",
    "    average_X = np.cumsum(Xs) / np.arange(1, num_trials + 1)\n",
    "    average_Y = np.cumsum(Ys) / np.arange(1, num_trials + 1)\n",
    "\n",
    "\n",
    "    fix, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axs[0].plot(range(1, num_trials + 1), average_X)\n",
    "    axs[0].set_xlabel('Number of trials')\n",
    "    axs[0].set_ylabel('Average')\n",
    "    axs[0].set_title('Average number of heads')\n",
    "\n",
    "    axs[1].plot(range(1, num_trials + 1), average_Y)\n",
    "    axs[1].set_xlabel('Number of trials')\n",
    "    axs[1].set_ylabel('Average')\n",
    "    axs[1].set_title('Average number of heads == 2?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa0928",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdba727",
   "metadata": {},
   "source": [
    "# Statistical Inference Pipeline\n",
    "Suppose $\\Xn$ is sampled iid from a distribution $D(\\theta)$ where $\\theta$ is a sample of size $n$ from a distribution $D$ with parameter $\\theta$.\n",
    "\n",
    "Then, intuitively, a statistic $\\hat\\theta \\equiv \\hat\\theta(\\Xn)$ is the **best guess** for the parameter $\\theta$.\n",
    "\n",
    "The main difference between **statsical inference pipeline** and **data analysis pipeline** is that we make this assumption that we try to understand the underlaying distribution of the data generating process. The only way that we can understand it is through $X_1, X_2, ... ,X_n$. The data we are analyzing is **one inatcne of the sample form the universe of the sample that we could have observed**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f1f96",
   "metadata": {},
   "source": [
    "## Sampling Distribution\n",
    "\n",
    "Since $\\Xn$ are all random variables, the statistic $\\hat\\theta$ is also random.\n",
    "\n",
    "> In words, the **sampling distribution** of $\\hat\\theta$ is the distribution $\\hat\\theta$ when $X_1, ...\\Xn$ are drawn from $D(\\theta)$, which depends on:\n",
    "\n",
    "- the  distribution $D$,\n",
    "- the parameter $\\theta$, and\n",
    "- the sample size $n$.\n",
    "\n",
    "All of hypothesis testing boils down to understanding this sampling distribution that we have. The **sampling distribution** gives the exact charactization of the underlaying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb0ec0",
   "metadata": {},
   "source": [
    "### Intuition behind Sampling Distributions\n",
    "\n",
    "If we call the process of sampling $\\Xn$ from $D(\\theta)$ as a \"**random experiment**\", then let\n",
    "\n",
    "* $\\hat\\theta^{(1)}, \\hat\\theta^{(1)}, \\dots, \\hat\\theta^{(N)}$ be the statistics obtained from each of $N$ random experiments.\n",
    "\n",
    "Then, the sampling distribution of $\\hat\\theta$ roughly is a **theoritical formulation** of how that sampling distribution shoul  look like.\n",
    "\n",
    "- **1st experiment:**\n",
    "  - $X_1^{(1)}, X_2^{(1)}, \\dots, X_n^{(1)} \\sim D(\\theta)$ and\n",
    "  - $\\hat{\\theta}^{(1)}$ is the statistic computed from this sample.\n",
    "\n",
    "- **2nd experiment:**\n",
    "  - $X_1^{(2)}, X_2^{(2)}, \\dots, X_n^{(2)} \\sim D(\\theta)$ and\n",
    "  - $\\hat{\\theta}^{(2)}$ is the statistic computed from this sample.\n",
    "\n",
    "- **3rd experiment:**\n",
    "  - $X_1^{(3)}, X_2^{(3)}, \\dots, X_n^{(3)} \\sim D(\\theta)$ and\n",
    "  - $\\hat{\\theta}^{(3)}$ is the statistic computed from this sample.\n",
    "\n",
    "- **N-th experiment:**\n",
    "  - $X_1^{(N)}, X_2^{(N)}, \\dots, X_n^{(N)} \\sim D(\\theta)$ and\n",
    "  - $\\hat{\\theta}^{(N)}$ is the statistic computed from this sample.\n",
    "\n",
    "If we look at the histogram of $\\hat{\\theta}^{(1)}, \\hat{\\theta}^{(2)}, \\dots, \\hat{\\theta}^{(N)}$, we get an approximation of the sampling distribution of $\\hat{\\theta}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdae2d8",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "Suppose $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta)$ and $\\hat{\\theta} = \\overline{X}$ is the sample proportion.\n",
    "\n",
    "Then, the sampling distribution of $\\hat{\\theta}$ is:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\sim \\frac{1}{n} \\text{Bin}(n, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb109715",
   "metadata": {},
   "source": [
    "We will use the `stats` module to illustrate each of the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.4134\n",
    "n, N = 100, 10000\n",
    "theta_hats = [stats.bernoulli(p).rvs(n).sum() for _ in range(N)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.histplot(theta_hats, ax=ax[0], stat='density', color='red')\n",
    "plot_X(stats.binom(n, p), ax[1], type='pmf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99ca21",
   "metadata": {},
   "source": [
    "Suppose $X_n \\sim N(\\mu, \\sigma^2)$ and $\\hat\\mu = \\overline{X}$ is the sample mean. \n",
    "\n",
    "Then, the sampling distribution of $\\hat\\mu$ is:\n",
    "\n",
    "$$\n",
    "\\hat\\mu \\sim N(\\mu, \\sigma^2/n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186508ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 3.141, 2.718\n",
    "n, N = 100, 1000\n",
    "theta_hats = [stats.norm(mu, sigma).rvs(n).mean() for _ in range(N)]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "sns.histplot(theta_hats, ax=ax, stat='density', color='red')\n",
    "plot_X(stats.norm(mu, sigma/np.sqrt(n)), ax, type='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453f517",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332e8a9",
   "metadata": {},
   "source": [
    "## Confidence Interval\n",
    "**This would help greatly to quantify uncertainties from complex models, what if $X_1, X_2, ..., X_n$ does not come from  Nernulli R.V. but rather a image varaibale?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942673c",
   "metadata": {},
   "source": [
    "The **$100 \\times (1-\\alpha)\\%$ confidence interval** for a parameter $\\theta$ is an interval $[\\la, \\ua]$ such that:\n",
    "\n",
    "$$\n",
    "P(l_{\\alpha} \\leq \\theta \\leq u_{\\alpha}) \\geq 1 - \\alpha\n",
    "$$\n",
    "\n",
    "we denote this as $\\ci(\\theta) = [\\la, \\ua]$.\n",
    "\n",
    "The underlaying **randomness** in here is teh **end point** of the interval. The interval is a **random interval** since the end points are the random variables, depending on the **sample that we collect** (depends on sample size, statistics, sample themselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e495559e",
   "metadata": {},
   "source": [
    "### Consider the following experiment:\n",
    "\n",
    "- You go and ask \\(n = 100\\) people at UCSD whether or not they are part of a club.\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{cases} \n",
    "1 & \\text{if the student is part of a club} \\\\\n",
    "0 & \\text{if the student is NOT part of a club}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Their responses are assumed to be $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta)$.\n",
    "- Here $\\theta$ is the true proportion of people at UCSD who are part of a club.\n",
    "\n",
    "Let’s assume that I know the true value of $\\theta$ to be $\\theta = 0.646$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc757077",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_true = 0.646 # we don't know this ahead of time\n",
    "\n",
    "def ask_survey(n):\n",
    "    return stats.bernoulli.rvs(theta_true, size=n)\n",
    "\n",
    "responses = ask_survey(100)\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04ba07",
   "metadata": {},
   "source": [
    "Our best **guess** for the true value of $\\theta$ is the sample proportion:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "Here, $\\hat{\\theta}$ is the **statistic** and $\\theta$ is the **parameter**. Notice that\n",
    "\n",
    "- The true population parameter $\\theta$ is a fixed value.\n",
    "- The statistics $\\hat{\\theta}$ is  a random varaibale that depends on the smaple.\n",
    "\n",
    "Hence different samples have different  $\\hat{\\theta}$. The crucial part of CI is that we can have much more data from just having fewer actual experiment (**capture more variability**), **we what to capture what the majority of the observation is trying to convey.**\n",
    "\n",
    "- Instead of reporting just one $\\hat{\\theta}$, we can do better and report a interval that contains the majority of the randomness in $\\hat{\\theta}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = [ask_survey(100) for _ in range(1000)]\n",
    "theta_hats = np.array([np.mean(survey) for survey in surveys])\n",
    "theta_hats[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397768c6",
   "metadata": {},
   "source": [
    "For a statistic $\\hat\\theta$ with standard error $\\se(\\hat\\theta)$ the general formula for the $100 \\times (1-\\alpha)\\%$ confidence interval is given by the following.\n",
    "\n",
    "- You calculate $\\hat\\theta$\n",
    "- You calculate the SE, which discusses about standard deviations\n",
    "- You calculate  an interval\n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta)$ be a random sample of size $n$ from a population with proportion $\\theta$. The $100 \\times (1 - \\alpha)\\%$ confidence interval for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\theta, \\alpha) = \\left[\\hat{\\theta} - z_{\\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\theta} + z_{\\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\left[\\hat{\\theta} - z_{\\alpha/2} \\sqrt{\\frac{\\hat{\\theta}(1 - \\hat{\\theta})}{n}}, \\; \\hat{\\theta} + z_{\\alpha/2} \\sqrt{\\frac{\\hat{\\theta}(1 - \\hat{\\theta})}{n}}\\right]\n",
    "$$\n",
    "\n",
    "where $z_{\\alpha/2}$ is the $(1 - \\alpha/2)$ quantile of the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69b0b9",
   "metadata": {},
   "source": [
    "Things tends to be `Bernulli distributed` in real life, so let's choose a random survey following Bernulli distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(f'{surveys[i]}, \\n \\n {np.mean(surveys[i])}, {theta_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_1proportion(sample, alpha):\n",
    "    n = len(sample)\n",
    "    Z = stats.norm(0, 1)\n",
    "    z_alpha_by_2 = Z.ppf(1-alpha/2)\n",
    "    \n",
    "    theta_hat = np.mean(sample)\n",
    "    se = np.sqrt(theta_hat * (1-theta_hat) / n)\n",
    "    ci = np.array((-1, +1)) * z_alpha_by_2 * se + theta_hat\n",
    "    return ci\n",
    "\n",
    "alpha = 0.05\n",
    "CI_1proportion(surveys[20], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[CI_1proportion(survey, alpha) for survey in surveys][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfb908",
   "metadata": {},
   "source": [
    "The `red` lines are the sampels that does not include the true population statistics within the confidence interval: of course, we wouldn't know this before head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 3))\n",
    "cis = [CI_1proportion(survey, alpha) for survey in surveys]\n",
    "\n",
    "ax.axhline(y=theta_true, color='red', linestyle='--')\n",
    "ax.set_ylabel(r'CI($\\theta$, 0.05)')\n",
    "for i, ci in enumerate(cis):\n",
    "    cl = 'black' if ci[0] <= theta_true <= ci[1] else 'red'\n",
    "    ax.plot([i, i], ci, color=cl, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b47f3b",
   "metadata": {},
   "source": [
    "We can calculate this proportion of \"out of all samples\" the samples that have the CI that contaisn the opulation statistics, this is **coverage probability**, which is essetially $1 - \\alpha$ governed by statistics laws."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0969938",
   "metadata": {},
   "source": [
    "### Interpretation of Confidence Intervals\n",
    "\n",
    "Let's assume that each of our randome xperiment has a random variable as random outcome. If we call the process of sampling $X_n$ from $D(\\theta)$ as a \"**random experiment**\" where $\\theta^*$ is the true, unknown population parameter.  \n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "[\\la^{(1)}, \\ua^{(1)}], [\\la^{(2)}, \\ua^{(2)}], \\dots, [\\la^{(N)}, \\ua^{(N)}]\n",
    "$$\n",
    "\n",
    "be the $100 \\times (1-\\alpha)\\%$ confidence intervals obtained from each of $N$ random experiments.\n",
    "\n",
    "Then, the guarantee provided by the construction of the confidence interval is that **if I replicate this process any number of times, we will have $100 \\times (1-\\alpha)\\%$ confidence that the true population parameter $\\theta$ will be in this rabndom interval**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a255fc",
   "metadata": {},
   "source": [
    "### Coverage probability\n",
    "\n",
    "The coverage probability of a confidence interval says if I replicate this process of collecting data, compute confidence interval, and check the population parameters, **it is fraction of time that my experiment contaisn the true population parameter $\\theta$**.\n",
    "\n",
    "Now more specifically, the confidence interval with a given level of confidence must have the **coverage probability** of $1 - \\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d97ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = np.mean([ci[0] <= theta_true <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_respondents, num_surveys = 1000, 10000\n",
    "surveys = [ask_survey(num_respondents) for _ in range(num_surveys)]\n",
    "cis = [CI_1proportion(survey, alpha) for survey in surveys]\n",
    "coverage = np.mean([ci[0] <= theta_true <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b75da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d124d",
   "metadata": {},
   "source": [
    "# Examples of Confidence Intervals\n",
    "\n",
    "This CI process holds for any types of distributions. The statistcis you use should be valid for the **assumptions you made for the data taht you have**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00a0b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55bd2a",
   "metadata": {},
   "source": [
    "## §1. One Sample Proportion\n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta)$ be a random sample of size $n$ from a population with proportion $\\theta$. **Sum of many many bernulli is a ngaussian distribution**.\n",
    "\n",
    "| Description            | Answer                       |\n",
    "|:-----------------------|:-----------------------------|\n",
    "| Assumption             | $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta)$ |\n",
    "| Population parameter   | $\\theta = \\theta \\text{ or } P(\\text{success})$ |\n",
    "| Statistic              | $\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^n X_i$ |\n",
    "| Standard Error         | $\\text{SE}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\theta}(1 - \\hat{\\theta})}{n}}$ |\n",
    "| Sampling distribution  | $D_{\\hat{\\theta}} = \\mathcal{N}(\\theta, \\text{SE}^2)$ |\n",
    "\n",
    "The **99\\% confidence interval** for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\theta, \\alpha) = \\left[\\hat{\\theta} - z_{\\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\theta} + z_{\\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca498063",
   "metadata": {},
   "source": [
    "Example of this is the one above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe39fa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4485883",
   "metadata": {},
   "source": [
    "## §2. Difference of Two Proportions\n",
    "\n",
    "Remanber that the **sum of many many bernulli is a gaussian distribution**. Let:\n",
    "\n",
    "- $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta_X)$ be a random sample of size $n$ from a population with proportion $\\theta_X$.\n",
    "- $Y_1, Y_2, \\dots, Y_m \\sim \\text{Ber}(\\theta_Y)$ be a random sample of size $m$ from a population with proportion $\\theta_Y$.\n",
    "\n",
    "Then:\n",
    "\n",
    "- The parameter of interest is $\\theta_X - \\theta_Y$ ($\\theta_i$ may be parameters from two different hypothesis).\n",
    "- The statistic of interest is $\\hat{\\theta} = \\hat{\\theta}_X - \\hat{\\theta}_Y$.\n",
    "\n",
    "| Description            | Answer                                                |\n",
    "|:-----------------------|:------------------------------------------------------|\n",
    "| Assumption             | $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(\\theta_X)$ and $Y_1, Y_2, \\dots, Y_m \\sim \\text{Ber}(\\theta_Y)$ |\n",
    "| Population parameter   | $\\theta = \\theta_X - \\theta_Y$                        |\n",
    "| Statistic              | $\\hat{\\theta} = \\hat{\\theta}_X - \\hat{\\theta}_Y$      |\n",
    "| Standard Error         | $\\text{SE}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\theta}_X (1 - \\hat{\\theta}_X)}{n} + \\frac{\\hat{\\theta}_Y (1 - \\hat{\\theta}_Y)}{m}}$ |\n",
    "| Sampling distribution  | $D_{\\hat{\\theta}} = \\mathcal{N}(\\theta, \\text{SE}^2)$ |\n",
    "\n",
    "The **97\\% confidence interval** for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\theta, \\alpha) = \\left[\\hat{\\theta} - z_{\\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\theta} + z_{\\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$\n",
    "\n",
    "Suppose we know that $\\theta_X = 0.646$ and $\\theta_Y = 0.628$. Let's see how well our confidence interval does.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_x = 0.646\n",
    "theta_y = 0.628\n",
    "\n",
    "def ask_surveys(n, m):\n",
    "    return {\n",
    "        'x': stats.bernoulli.rvs(theta_x, size=n), \n",
    "        'y': stats.bernoulli.rvs(theta_y, size=m)\n",
    "    }\n",
    "\n",
    "ask_surveys(n=50, m=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2257560",
   "metadata": {},
   "source": [
    "* The true value of $\\theta$ is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\theta &= \\theta_X - \\theta_Y\\\\ \n",
    "&= 0.646 - 0.628 \\\\\n",
    "&= 0.018.\n",
    "\\end{aligned}\n",
    "$$ \n",
    "* The sample estimator is \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat\\theta &= \\hat{\\theta}_X - \\hat{\\theta}_Y\\\\ &= \\overline{X} - \\overline{Y}.\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = lambda survey: np.mean(survey['x']) - np.mean(survey['y'])\n",
    "\n",
    "survey = ask_surveys(50, 40)\n",
    "theta_hat(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_2proportion(survey, alpha):\n",
    "    n, m = len(survey['x']), len(survey['y'])\n",
    "    theta_hat = np.mean(survey['x']) - np.mean(survey['y'])\n",
    "    se = np.sqrt(np.mean(survey['x']) * (1 - np.mean(survey['x'])) / n + np.mean(survey['y']) * (1 - np.mean(survey['y'])) / m)\n",
    "    Z = stats.norm(0, 1)\n",
    "    z_alpha_by_2 = Z.ppf(1-alpha/2)\n",
    "    ci = np.array((-1, +1)) * z_alpha_by_2 * se + theta_hat\n",
    "    return ci\n",
    "\n",
    "CI_2proportion(survey, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_surveys = 2500\n",
    "surveys = [ask_surveys(50, 40) for _ in range(num_surveys)]\n",
    "theta_hats = np.array([theta_hat(survey) for survey in surveys])\n",
    "cis = [CI_2proportion(survey, alpha) for survey in surveys]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 3))\n",
    "\n",
    "ax.axhline(y=theta_x-theta_y, color='red', linestyle='--')\n",
    "ax.set_ylabel(r'CI($\\theta$, 0.05)')\n",
    "ax.set_xlabel('Survey number')\n",
    "for i, ci in enumerate(cis):\n",
    "    cl = 'black' if ci[0] <= theta_x - theta_y <= ci[1] else 'red'\n",
    "    ax.plot([i, i], ci, color=cl, linewidth=1.0)\n",
    "    \n",
    "coverage = np.mean([ci[0] <= theta_x - theta_y <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, num_surveys = 1000, 2000, 50000\n",
    "surveys = [ask_surveys(n, m) for _ in range(num_surveys)]\n",
    "cis = [CI_2proportion(survey, alpha) for survey in surveys]\n",
    "coverage = np.mean([ci[0] <= theta_x - theta_y <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c767f08",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0067c9",
   "metadata": {},
   "source": [
    "## §3. One Sample Mean (Known Variance)\n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$ be a random sample of size $n$ from a population with mean $\\mu$ and variance $\\sigma^2$. We will be talking about gaussian distribution here because only in this sense talking about $\\mu$ and $\\sigma$ makes sense. Let:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\quad \\text{be the sample mean}\n",
    "$$\n",
    "\n",
    "\n",
    "| Description            | Answer                                                |\n",
    "|:-----------------------|:------------------------------------------------------|\n",
    "| Assumption             | $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$ |\n",
    "| Population parameter   | $\\theta = \\mu$                                        |\n",
    "| Statistic              | $\\hat{\\theta} = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i$ |\n",
    "| Standard Error         | $\\text{SE}(\\hat{\\theta}) = \\frac{\\sigma}{\\sqrt{n}}$|\n",
    "| Sampling distribution  | $D_{\\hat{\\theta}} = \\mathcal{N}(\\mu, \\text{SE}^2)$    |\n",
    "\n",
    "The **93\\% confidence interval** for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\mu, \\alpha) = \\left[\\hat{\\mu} - z_{\\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\mu} + z_{\\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07df02a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d2f01",
   "metadata": {},
   "source": [
    "## §3. One Sample Mean (Unknown Variance)\n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$ be a random sample of size $n$ from a population with mean $\\mu$ and variance $\\sigma^2$.\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\quad \\text{be the sample mean}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n - 1} \\sum_{i=1}^n (X_i - \\overline{X})^2 \\quad \\text{be the (unbiased) sample variance}\n",
    "$$\n",
    "\n",
    "**The best thing you can do when $\\sigma$ is unpresented is to plug in \\hat{\\sigma} witht the tradeoff og using student t-distribution.** This is the usual case that we will be seeing as well.\n",
    "\n",
    "| Description            | Answer                                                |\n",
    "|:-----------------------|:------------------------------------------------------|\n",
    "| Assumption             | $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$ |\n",
    "| Population parameter   | $\\theta = \\mu$                                        |\n",
    "| Statistic              | $\\hat{\\theta} = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i$ |\n",
    "| Standard Error         | $\\text{SE}(\\hat{\\theta}) = \\frac{\\hat{\\sigma}}{\\sqrt{n}}$, where $\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}$ |\n",
    "| Sampling distribution  | $D_{\\hat{\\theta}} = \\mathcal{N}(\\mu, \\text{SE}^2)$    |\n",
    "\n",
    "The **93\\% confidence interval** for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\mu, \\alpha) = \\left[\\hat{\\mu} - t_{n-1, \\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\mu} + t_{n-1, \\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250c671",
   "metadata": {},
   "source": [
    "Consider the following experiment:\n",
    "\n",
    "- You go and ask $n = 20$ people at UCSD how many hours they sleep per night.\n",
    "- $X_i =$ number of hours respondent $i$ sleeps per night.\n",
    "\n",
    "- Their responses are assumed to be $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "- Here $\\mu$ is the **true average number of hours** people at UCSD sleep per night.\n",
    "\n",
    "Let’s assume that **I know** the true value of $\\mu$ to be $\\mu = 7.2$ hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26998028",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = 7.2\n",
    "\n",
    "def sleep_survey(n):\n",
    "    return stats.norm.rvs(mu_true, 2.5, size=n)\n",
    "\n",
    "survey = sleep_survey(20)\n",
    "survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true, np.mean(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_1mean(data, alpha=0.05, method='t'):\n",
    "    n = len(data)\n",
    "    q_alpha_by_2 = stats.t(n-1).ppf(1-alpha/2) if method == 't' else stats.norm(0, 1).ppf(1-alpha/2)\n",
    "    \n",
    "    mu_hat = np.mean(data)\n",
    "    se = np.std(data, ddof=1) / np.sqrt(n)\n",
    "    ci = np.array((-1, +1)) * q_alpha_by_2 * se + mu_hat\n",
    "    return ci\n",
    "\n",
    "CI_1mean(survey, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "num_respondents, num_surveys = 10, 250\n",
    "surveys = [sleep_survey(10) for _ in range(num_surveys)]\n",
    "cis = [CI_1mean(survey, alpha) for survey in surveys]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 3))\n",
    "\n",
    "ax.axhline(y=mu_true, color='red', linestyle='--')\n",
    "ax.set_ylabel(r'CI($\\mu$, 0.05)')\n",
    "ax.set_xlabel('Survey number')\n",
    "for i, ci in enumerate(cis):\n",
    "    cl = 'black' if ci[0] <= mu_true <= ci[1] else 'red'\n",
    "    ax.plot([i, i], ci, color=cl, linewidth=1.0)\n",
    "    \n",
    "coverage = np.mean([ci[0] <= mu_true <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d022f",
   "metadata": {},
   "source": [
    "Does using gaussian distribution or student's distribution makes  difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa953eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(n = (2, 50, 1))\n",
    "def z_vs_t_coverage(n):\n",
    "    num_surveys = 5000\n",
    "    surveys = [sleep_survey(n) for _ in range(num_surveys)]\n",
    "    ci_z = [CI_1mean(survey, alpha, method='z') for survey in surveys]\n",
    "    ci_t = [CI_1mean(survey, alpha, method='t') for survey in surveys]\n",
    "\n",
    "    coverage_z = np.mean([ci[0] <= mu_true <= ci[1] for ci in ci_z])\n",
    "    coverage_t = np.mean([ci[0] <= mu_true <= ci[1] for ci in ci_t])\n",
    "\n",
    "    print({'z coverage': coverage_z, 't coverage': coverage_t})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a345c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d71598",
   "metadata": {},
   "source": [
    "## §4. Difference of Two Means (Unknown Variances)\n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)$ be a random sample of size $n$ from a population with mean $\\mu$ and variance $\\sigma^2$.\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\quad \\text{be the sample mean}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n - 1} \\sum_{i=1}^n (X_i - \\overline{X})^2 \\quad \\text{be the (unbiased) sample variance}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{\\sigma}_X^2 &= \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2 \\quad\\quad \\text{is the sample variance of $X$}\\\\\n",
    "\\hat{\\sigma}_Y^2 &= \\frac{1}{m-1} \\sum_{i=1}^m (Y_i - \\overline{Y})^2 \\quad\\quad \\text{is the sample variance of $Y$}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and that\n",
    "\n",
    "- $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)$ be a random sample of size $n$ from a population with mean $\\mu_X$ and variance $\\sigma_X^2$.\n",
    "- $Y_1, Y_2, \\dots, Y_m \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y^2)$ be a random sample of size $m$ from a population with mean $\\mu_Y$ and variance $\\sigma_Y^2$.\n",
    "\n",
    "| Description            | Answer                                                |\n",
    "|:-----------------------|:------------------------------------------------------|\n",
    "| Assumption             | $X_1, X_2, \\dots, X_n \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)$ and $Y_1, Y_2, \\dots, Y_m \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y^2)$ |\n",
    "| Population parameter   | $\\theta = \\mu_X - \\mu_Y$                              |\n",
    "| Statistic              | $\\hat{\\theta} = \\overline{X} - \\overline{Y}$          |\n",
    "| Standard Error         | $\\text{SE}(\\hat{\\theta}) = \\sqrt{\\frac{\\hat{\\sigma}_X^2}{n} + \\frac{\\hat{\\sigma}_Y^2}{m}}$ |\n",
    "| Sampling distribution  | $D_{\\hat{\\theta}} = \\mathcal{N}(\\theta, \\text{SE}^2)$ |\n",
    "\n",
    "The **96\\% confidence interval** for $\\theta$ is given by:\n",
    "\n",
    "$$\n",
    "CI(\\theta, \\alpha) = \\left[\\hat{\\theta} - z_{\\alpha/2} \\cdot \\text{SE}, \\; \\hat{\\theta} + z_{\\alpha/2} \\cdot \\text{SE}\\right]\n",
    "$$\n",
    "\n",
    "* You go and ask $n=15$ freshmen and $m=20$ seniors at UCSD how many hours they sleep per night.\n",
    "* Suppose we know that $\\mu_X = 7.2$ and $\\mu_Y = 6.2$. Let's see how well our confidence interval does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_x = 7.2\n",
    "mu_y = 6.2\n",
    "mu_xy = mu_x - mu_y\n",
    "\n",
    "s_x, s_y = 2.5, 2.0\n",
    "\n",
    "def sleep_surveys(n, m):\n",
    "    return {\n",
    "        'x': stats.norm.rvs(mu_x, 2.5, size=n), \n",
    "        'y': stats.norm.rvs(mu_y, 2.0, size=m)\n",
    "    }\n",
    "\n",
    "survey = sleep_surveys(15, 20)\n",
    "survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a800de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI_2mean(survey, alpha=0.05, method='t'):\n",
    "    n, m = len(survey['x']), len(survey['y'])\n",
    "    mu_hat = np.mean(survey['x']) - np.mean(survey['y'])\n",
    "    se = np.sqrt(np.std(survey['x'], ddof=1)**2 / n + np.std(survey['y'], ddof=1)**2 / m)\n",
    "    q_alpha_by_2 = stats.t(n+m-2).ppf(1-alpha/2) if method == 't' else stats.norm(0, 1).ppf(1-alpha/2)\n",
    "    ci = np.array((-1, +1)) * q_alpha_by_2 * se + mu_hat\n",
    "    return ci\n",
    "\n",
    "CI_2mean(survey, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_2mean(survey, alpha=0.05)[0] <= mu_xy <= CI_2mean(survey, alpha=0.05)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, num_surveys = 5, 7, 10000\n",
    "surveys = [sleep_surveys(n, m) for _ in range(num_surveys)]\n",
    "cis = [CI_2mean(survey, alpha) for survey in surveys]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 3))\n",
    "\n",
    "ax.axhline(y=mu_xy, color='red', linestyle='--')\n",
    "ax.set_ylabel(r'CI($\\mu_X - \\mu_Y$, 0.05)')\n",
    "ax.set_xlabel('Survey number')\n",
    "for i, ci in enumerate(cis):\n",
    "    cl = 'black' if ci[0] <= mu_xy <= ci[1] else 'red'\n",
    "    ax.plot([i, i], ci, color=cl, linewidth=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0061302",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = np.mean([ci[0] <= mu_xy <= ci[1] for ci in cis])\n",
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbf422",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m, num_surveys = 5, 10, 10000\n",
    "surveys = [sleep_surveys(n, m) for _ in range(num_surveys)]\n",
    "cis = [CI_2mean(survey, alpha) for survey in surveys]\n",
    "coverage = [ci[0] <= mu_xy <= ci[1] for ci in cis]\n",
    "print(f'coverage probability: {np.mean(coverage):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c007459",
   "metadata": {},
   "source": [
    "However, this seems to not be as `accurate` as what we have seen in previous examples, we didn't get that `95%` coverage that we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f173ed0",
   "metadata": {},
   "source": [
    "### Welch-Satterthwaite Approximation\n",
    "\n",
    "When you look at the distribution of differences in means, just using t-distribution is inaccurate.\n",
    "\n",
    "- The $t_{n+m-2}$ distribution is a reasonable approximation of the **sampling distribution**.\n",
    "- But, the **Welch-Satterthwaite approximation** is much better and results in $t_k$—a t-distribution with:\n",
    "\n",
    "$$\n",
    "k = \\frac{\\left(\\frac{\\sigma_X^2}{n} + \\frac{\\sigma_Y^2}{m}\\right)^2}{\\frac{\\sigma_X^4}{n^2(n-1)} + \\frac{\\sigma_Y^4}{m^2(m-1)}}\n",
    "$$\n",
    "\n",
    "degrees of freedom.\n",
    "\n",
    "NOTICE: Welch-Satterthwaite approximation is still an approximation, the actual degree of expansion is hidden by some infinite Taylor exapnsion. The `statsmodels` library uses the Welch-Satterthwaite approximation by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561284ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "survey = surveys[i]\n",
    "\n",
    "xy_object = sm.stats.CompareMeans(\n",
    "    sm.stats.DescrStatsW(survey['x']), \n",
    "    sm.stats.DescrStatsW(survey['y'])\n",
    ")\n",
    "\n",
    "our_result = CI_2mean(survey, alpha=0.05)\n",
    "print(f'Our method: {our_result}')\n",
    "\n",
    "sm_result = xy_object.tconfint_diff(alpha=0.05, usevar='unequal')\n",
    "print(f'Statsmodels api: {sm_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(n = (2, 50, 1))\n",
    "def z_vs_t_coverage(n):\n",
    "    num_surveys = 10000\n",
    "    surveys = [sleep_surveys(n, n) for _ in range(num_surveys)]\n",
    "    our_ci = [CI_2mean(survey, alpha=0.05, method='t') for survey in surveys]\n",
    "    \n",
    "    sm_ci  = np.zeros((num_surveys, 2))\n",
    "    for i, survey in enumerate(surveys):\n",
    "        xy_object = sm.stats.CompareMeans(\n",
    "            sm.stats.DescrStatsW(survey['x']), \n",
    "            sm.stats.DescrStatsW(survey['y'])\n",
    "        )\n",
    "        sm_ci[i, :] = xy_object.tconfint_diff(alpha=0.05, usevar='unequal')\n",
    "\n",
    "\n",
    "    our_coverage = np.mean([ci[0] <= mu_xy <= ci[1] for ci in our_ci])\n",
    "    sm_coverage = np.mean([ci[0] <= mu_xy <= ci[1] for ci in sm_ci])\n",
    "\n",
    "    print({'our coverage': our_coverage, 'sm coverage': sm_coverage})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378875f",
   "metadata": {},
   "source": [
    "We see that `Welch-Satterthwaite Approximation`  does help a bit, though not a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f20707",
   "metadata": {},
   "source": [
    "To eavluate which method is better, we need to define what is better, which in this case would be having a `coverage probability that is closer to the assumption that we are making`, which is that a 95% CI should contain 95% of the true parameter $\\theta$ in it. For differences in mean, we can observe that from part f, Welch's t-test has a coverage probability closer to 95 (what we defined with our $\\alpha$ value) when comparing to student's t-test, hence, Welch's t-test is  more accurate to be used as student's t-test in here post too wide of an interval that plays too conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57117d16",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92278c55",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "\n",
    "* Suppose we have a collection $X_1, X_2, \\dots, X_n \\sim D(\\theta)$, observed iid from a distribution $D$ with unknown population parameter $\\theta$.\n",
    "\n",
    "* We want to understand whether the true population parameter $\\theta$ is equal to some value $\\theta_0$.\n",
    "\n",
    "* We do this by constructing a **hypothesis test**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd3c4f",
   "metadata": {},
   "source": [
    "## Anatomy of Statistical Hypothesis Test:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974d0a8",
   "metadata": {},
   "source": [
    "> 1. Assumption: this is the assumption that $X_1, X_2, \\dots, X_n \\sim D(\\theta)$ from which we **draw our data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dfc21",
   "metadata": {},
   "source": [
    "> 2. Population Parameter: under the assumptions above, the **population parameter $\\theta$ encodes some information about the population** which we want to infer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12aa4c1",
   "metadata": {},
   "source": [
    "\n",
    "> 3. Null Hypothesis: $H_0$ is a statement about the value of $\\theta$ under the **most conservative** assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ae460",
   "metadata": {},
   "source": [
    "> 4. Alternate hypothesis $H_a$ is a statement about the value of $\\theta$ you **want to show evidence in favor of**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11355985",
   "metadata": {},
   "source": [
    "> 5. Sample statistic: the sample statistic $\\hat{\\theta}$ is a function of the data that we use to estimate $\\theta$. This is our **best guess**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a26dbd",
   "metadata": {},
   "source": [
    "> 6. Test statistic: $\\hat{T} = \\hat{T}(X_1, X_2, \\dots, X_n)$ is a **function of the data that we use to decide between $H_0$ and $H_a$**. This is random, we use this to decide if we want to reject. teh Null, but not to prove it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b319b",
   "metadata": {},
   "source": [
    "> 7. Rejection region $R(\\hat{T}, \\alpha)$ is a **set of values of $\\hat{T}$ for which we reject $H_0$** from the set of all possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a755a51",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "Given two hypotheses we want to test, there are the following `four scenarios` which can happen:\n",
    "\n",
    "| Decision / Truth | $H_0$ is true  | $H_a$ is true  |\n",
    "|------------------|----------------|----------------|\n",
    "| Fail to reject $H_0$ | Correct         | Type II error  |\n",
    "| Reject $H_0$         | Type I error    | Correct        |\n",
    "\n",
    "\n",
    "1. Null is true but we reject $H_0$ (Type-One: not significant but we say significant)\n",
    "2. Null is false and we does reject $H_0$ (correct)\n",
    "3. Alternative is true but we fail to reject $H_0$ (Type-Two: significant but we say not significant)\n",
    "4. Alternative is true and we does reject $H_0$ (correct)\n",
    "\n",
    "Generally speaking in `science`, making type-one is worst than type-two error. We don't want to claim that we found something siognificant but not actually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ece637",
   "metadata": {},
   "source": [
    "### **Significance level**  \n",
    "The probability of making a type-I Error.\n",
    "\n",
    "$$\n",
    "\\alpha = P(\\text{reject } H_0 \\mid H_0 \\text{ is true})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7cf23a",
   "metadata": {},
   "source": [
    "### **Power**  \n",
    "$1 - \\beta$ is the probability of making the right decision when $H_a$ is true.\n",
    "\n",
    "$$\n",
    "1 - \\beta = P(\\text{reject } H_0 \\mid H_a \\text{ is true})\n",
    "$$\n",
    "\n",
    "- $\\beta$ area is teh equivalence of Type-Two error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4f1fb",
   "metadata": {},
   "source": [
    "### **Example**\n",
    "\n",
    "You are a student at UCSD and you want to know if students at UCSD get the minimum recommended amount of sleep per night (7 hours).\n",
    "\n",
    "- You take a random sample of 100 students and ask them how many hours of sleep they get per night.\n",
    "- You find that the average amount of sleep is 6.5 hours per night.\n",
    "- You want to know if this is significant evidence that UCSD students get less than the recommended amount of sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11b1a0",
   "metadata": {},
   "source": [
    "| Anatomy of the hypothesis test | Answer                                       |\n",
    "|:------------------------------:|:--------------------------------------------:|\n",
    "| Assumption                     | Our data is real values: $X_1, X_2, \\dots, X_n \\sim N(\\mu, \\sigma^2)$ |\n",
    "| Population parameter           | $\\theta = \\mu$                               |\n",
    "| Sample statistic               | $\\hat{\\theta} = \\bar{X}$                     |\n",
    "| Test statistic                 | $T = \\frac{\\hat{\\theta} - \\theta}{\\hat{\\sigma} / \\sqrt{n}} \\sim t_{n-1}$ |\n",
    "| Null hypothesis                | $H_0: \\theta = 7$                            |\n",
    "| Alternate hypothesis           | $H_a: \\theta < 7$                            |\n",
    "| Rejection region shape         | ($-\\infty, x_{\\alpha}$)                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af2226",
   "metadata": {},
   "source": [
    "You are a student at UCSD and you want to see if the number of students who use the RIMAC gym is different from the number of students who use the Main Gym.\n",
    "\n",
    "- You take a random sample of 100 students and ask them if they use the RIMAC gym or the Main Gym.\n",
    "- You find that 60 of the students use the RIMAC gym and 40 of the students use the Main Gym.\n",
    "- You want to know if this is evidence that the proportion of students who use the RIMAC gym is more than the number of students who use the Main Gym.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776d5f8",
   "metadata": {},
   "source": [
    "| Anatomy of the hypothesis test | Answer                                                                                  |\n",
    "|:------------------------------:|:---------------------------------------------------------------------------------------:|\n",
    "| Assumption                     |Our data is boolean: $X_1, X_2, \\dots, X_n \\sim \\text{Ber}(p)$                           |\n",
    "| Population parameter           | $\\theta = p$                                                                            |\n",
    "| Sample statistic               | $\\hat{\\theta} = \\overline{X}$                                                           |\n",
    "| Test statistic                 | $T = \\displaystyle\\frac{\\hat{\\theta} - \\theta}{\\sqrt{\\frac{\\hat{\\theta} \\times (1 - \\hat{\\theta})}{n}}} \\approx N(0,1)$ |\n",
    "| Null hypothesis                | $H_0: \\theta = 0.5$                                                                     |\n",
    "| Alternate hypothesis           | $H_a: \\theta > 0.5$                                                                     |\n",
    "| Rejection region shape         | $(-\\infty, -x_\\alpha) \\cup (x_\\alpha, \\infty)$                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51c45d",
   "metadata": {},
   "source": [
    "You are a student at UCSD and want to determine if the average number of hours UCSD students spend studying per week is more than the national average of 15 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431cb143",
   "metadata": {},
   "source": [
    "| Anatomy of the hypothesis test | Answer                                                   |\n",
    "|--------------------------------|---------------------------------------------------------|\n",
    "| Assumption                     | $X_1, X_2, \\dots, X_n \\sim N(\\mu, \\sigma^2)$            |\n",
    "| Population parameter           | $\\theta = \\mu$, where $\\mu$ is the average study time per week |\n",
    "| Sample statistic               | $\\hat{\\theta} = \\overline{X}$ (sample mean study time)  |\n",
    "| Test statistic                 | $T = \\displaystyle\\frac{\\hat{\\theta} - \\theta}{s / \\sqrt{n}} \\sim t_{n-1}$ |\n",
    "| Null hypothesis                | $H_0: \\mu \\leq 15$                                         |\n",
    "| Alternate hypothesis           | $H_a: \\mu > 15$                                         |\n",
    "| Rejection region shape         | $T > t_\\alpha$                                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28611ce",
   "metadata": {},
   "source": [
    "### **Code Example**\n",
    "Suppose you ask a random sample of $n=15$ students at UCSD how many hours of sleep they get per night. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_MU = 6.5\n",
    "MU_0 = 7\n",
    "NUM_SURVEYS = 15\n",
    "\n",
    "def simulate_sleep_data(n):\n",
    "    return np.random.normal(TRUE_MU, 1, size=n)\n",
    "\n",
    "sleep_data = simulate_sleep_data(NUM_SURVEYS)\n",
    "sleep_data\n",
    "\n",
    "def simulate_null_data(n):\n",
    "    return np.random.normal(MU_0, 1, size=n)\n",
    "\n",
    "num_experiments = 1000\n",
    "null_data_replications = [simulate_null_data(NUM_SURVEYS) for _ in range(num_experiments)]\n",
    "\n",
    "def sleep_T_hat(data, MU):\n",
    "    return (data.mean() - MU) / (data.std(ddof=1) / np.sqrt(len(data)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax. hist([sleep_T_hat(x, MU_0) for x in null_data_replications], bins=20, density=True)\n",
    "plot_X(stats.t(14), ax, type='pdf', color='black', alpha=1.0, lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf187f",
   "metadata": {},
   "source": [
    "#### The observed test statistic $\\hat T$\n",
    "\n",
    "The observed test statistic which we got from the data is plotted in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_data.mean(), sleep_T_hat(sleep_data, MU_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hat = sleep_T_hat(sleep_data, MU_0)\n",
    "ax.vlines(t_hat, 0, 0.4, color='red', linestyles='--', lw=2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665c38d",
   "metadata": {},
   "source": [
    "#### Rejection region under the null hypothesis\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(\\hat T, \\alpha) &= (-\\infty, -x_\\alpha) \\\\\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9766858",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(alpha = (0.001, 0.999, 0.001))\n",
    "def rejection_region(alpha):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    # ax. hist([sleep_T_hat(x, MU_0) for x in null_data_replications], bins=20, density=True)\n",
    "    plot_X(stats.t(14), ax, type='pdf', color='black', alpha=1.0, lw=3)\n",
    "\n",
    "    ax.vlines(t_hat, 0, 0.4, color='red', linestyles='--', lw=2)\n",
    "    \n",
    "    x = np.linspace(-4, 4, 200)\n",
    "    ax.fill_between(x, 0, stats.t(14).pdf(x), where=x < stats.t(14).ppf(alpha), color='red', alpha=0.5)\n",
    "    ax.set_title(f'Rejection region for $\\\\alpha={alpha: .3f}$')\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738474a",
   "metadata": {},
   "source": [
    "## **The $p$-value**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98cf96",
   "metadata": {},
   "source": [
    "The $p$-value is the probability of **observing a test statistic as extreme or more extreme than the one we observed under the null hypothesis**, i.e.,\n",
    "\n",
    "$$\n",
    "p\\text{-value} = \\min \\left\\{ \\alpha \\in (0, 1) : \\hat{T} \\in R(\\hat{T}, \\alpha) \\right\\}\n",
    "$$\n",
    "\n",
    "- We are trying to say that it is very **unlikely** for us to observe the test statistics (random varaible) given a null distribution.\n",
    "\n",
    "Alternatively, we can discuss about the **test statistics's distribution** as well. If $T \\sim D(T_0)$ is the distribution of the test statistic under the null hypothesis, then\n",
    "\n",
    "$$\n",
    "p\\text{-value} =\n",
    "\\begin{cases}\n",
    "    P(D(T_0) \\leq \\hat{T}) & \\text{if } H_a : \\theta < 0 \\\\\n",
    "    P(D(T_0) \\geq \\hat{T}) & \\text{if } H_a : \\theta > 0 \\\\\n",
    "    2 \\times \\min \\{ P(D(T_0) \\leq \\hat{T}), P(D(T_0) \\geq \\hat{T}) \\} & \\text{if } H_a : \\theta \\neq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_0 = stats.t(14)\n",
    "p_value = DT_0.cdf(t_hat)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2417b87",
   "metadata": {},
   "source": [
    "this time we'll use the ``ttest_1samp`` function from ``scipy.stats``, there are a lot of good functions in this package, but they just may be kind of confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sleep_data, MU_0, alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15473cf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588fa18",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "We'll look at the `mtcars` dataset from this [excellent source](https://vincentarelbundock.github.io/Rdatasets/articles/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dcc9a",
   "metadata": {},
   "source": [
    "Is the average miles per gallon for cars in the `mtcars` dataset different from 20 mpg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf914fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"mpg\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46d2a8",
   "metadata": {},
   "source": [
    "| Anatomy of the hypothesis test |  Answer  |\n",
    "|:------------------------------:|:--------:|\n",
    "| Assumption                     | $$X_1, X_2, \\dots, X_n \\sim N(\\mu, \\sigma^2)$$ |\n",
    "| Population parameter           | $$\\theta = \\mu$$ |\n",
    "| Sample statistic               | $$\\hat\\theta = \\overline{X}$$ |\n",
    "| Test statistic                 | $$\\displaystyle T = \\frac{\\hat\\theta - \\theta}{\\text{SE}} \\approx t_{n-1}$$ |\n",
    "| Null hypothesis                | $$H_0: \\theta = 20$$ |\n",
    "| Alternate hypothesis           | $$H_a: \\theta \\neq 20$$ |\n",
    "| Rejection region shape         | $$(-\\infty, -x_\\alpha) \\cup (x_\\alpha, \\infty)$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02\n",
    "T, pvalue = stats.ttest_1samp(\n",
    "    df['mpg'], \n",
    "    20, \n",
    "    alternative='two-sided'\n",
    ")\n",
    "\n",
    "print(f'reject H0') if pvalue < alpha else print(f'fail to reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3522b",
   "metadata": {},
   "source": [
    "Are cars with 4 cylinders more fuel efficient than cars with 8 cylinders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a90a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.boxplot(x='cyl', y='mpg', data=df, hue='cyl', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a7d62",
   "metadata": {},
   "source": [
    "| Anatomy of the hypothesis test |  Answer  |\n",
    "|:------------------------------:|:--------:|\n",
    "| Assumption                     | $$X_n \\sim N(\\mux, \\sx^2)$$ and $$\\Ym \\sim N(\\mu_y, \\sy^2)$$ |\n",
    "| Population parameter           | $$\\theta = \\mux - \\muy$$ |\n",
    "| Sample statistic               | $$\\hat\\theta = \\overline{X} - \\overline{Y}$$ |\n",
    "| Test statistic                 | $$T = \\displaystyle\\frac{\\hat\\theta - \\theta}{\\se} \\sim t_{k}$$ |\n",
    "| Null hypothesis                | $$H_0: \\theta = 0$$ |\n",
    "| Alternate hypothesis           | $$H_a: \\theta > 0$$ |\n",
    "| Rejection region shape         | $$(x_\\alpha, \\infty)$$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-5\n",
    "\n",
    "T, pvalue = stats.ttest_ind(\n",
    "    df[df['cyl'] == 4]['mpg'], \n",
    "    df[df['cyl'] == 8]['mpg'], \n",
    "    equal_var=False,\n",
    "    alternative='greater'\n",
    ")\n",
    "\n",
    "print(f'reject H0') if pvalue < alpha else print(f'fail to reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99ff38",
   "metadata": {},
   "source": [
    "We will use the `covid-19` dataset from the [same source](https://vincentarelbundock.github.io/Rdatasets/articles/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://vincentarelbundock.github.io/Rdatasets/csv/medicaldata/covid_testing.csv'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004fc12",
   "metadata": {},
   "source": [
    "Do the number of positive COVID-19 tests in the `covid-19` exceed 5%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030dae7",
   "metadata": {},
   "source": [
    "> Not all tests in the dataset are COVID tests. We need to first remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523822f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('test_id')\n",
    "df = df[df.test_id == 'covid']\n",
    "df.test_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763329d5",
   "metadata": {},
   "source": [
    "> Not all covid tests are valid. We can remove them as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    df['result'].isin(['positive', 'negative'])\n",
    "]\n",
    "df.value_counts('result')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ded64",
   "metadata": {},
   "source": [
    "> Visulaizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.countplot(x='result', data=df, ax=ax)\n",
    "ax.hlines(5, -0.5, 1.5, color='red', linestyles='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "T, pvalue = statsmodels.stats.proportion.proportions_ztest(\n",
    "    count = df['result'].map(lambda x: x == 'positive').sum(),\n",
    "    nobs = df.shape[0],\n",
    "    value = 0.05,\n",
    "    alternative = 'larger'\n",
    ")\n",
    "\n",
    "print(f'reject H0') if pvalue < alpha else print(f'fail to reject H0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79c533",
   "metadata": {},
   "source": [
    "Do drive-through tests have a higher proportion of positive COVID-19 tests than walk-in tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b92e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['drive_thru_ind'], df['result']) / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2033241",
   "metadata": {},
   "source": [
    "> Two sample proportion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b17986",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "T, pvalue, statsmodels.stats.proportion.proportions_ztest(\n",
    "    count = [\n",
    "        df[df['drive_thru_ind'] == 1]['result'].map(lambda x: x == 'positive').sum(),\n",
    "        df[df['drive_thru_ind'] == 0]['result'].map(lambda x: x == 'positive').sum()\n",
    "    ],\n",
    "    nobs = [\n",
    "        df[df['drive_thru_ind'] == 0].shape[0],\n",
    "        df[df['drive_thru_ind'] == 0].shape[0]\n",
    "    ],\n",
    "    value = 0.0,\n",
    "    alternative = 'larger'\n",
    ")\n",
    "\n",
    "pvalue < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30545e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
