{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499b8cf",
   "metadata": {},
   "source": [
    "# Math 189 Week 7 Summary\n",
    "> NAME: $\\color{blue}{\\text{Kaiwen Bian}}$\n",
    "> \n",
    "> PID: $\\color{blue}{\\text{A17316568}}$\n",
    ">\n",
    "> \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce0cf8",
   "metadata": {},
   "source": [
    "I certify that the following write-up is my own work, and have abided by the UCSD Academic Integrity Guidelines.\n",
    "\n",
    "- [x] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c41b1",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$%$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$%$\n",
    "$\\forcecommand{\\supp}{\\text{supp}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\forcecommand{\\var}{\\text{Var}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\ci}{\\text{CI}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0120db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats as stats\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfec7ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6dc53",
   "metadata": {},
   "source": [
    "## Key Takeaways from Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f31",
   "metadata": {},
   "source": [
    "\n",
    "#### Tuesday: \n",
    "\n",
    "... insert your key takeaways here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69de7b",
   "metadata": {},
   "source": [
    "#### Thursday\n",
    "\n",
    "... insert your takeaway here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadbca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abad0d9",
   "metadata": {},
   "source": [
    "# Inference from Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f47b9",
   "metadata": {},
   "source": [
    "Consider the following regression model example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecc050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c3aaa91",
   "metadata": {},
   "source": [
    "There are qualitatively, **three different types of inference (`uncertainty quantification`)** that can be made from regression models:\n",
    "\n",
    "1. Hypothesis Testing\n",
    "2. Analysis of Variance\n",
    "3. General Linear Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313ab33",
   "metadata": {},
   "source": [
    "## Type 1: Examining Effects of Particular Variable\n",
    "\n",
    "The *p*-values for the coefficients are used to test the null hypothesis that the coefficient is zero, i.e.,\n",
    "\n",
    "$$\n",
    "H_0: \\beta_j = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: \\beta_j \\neq 0\n",
    "$$\n",
    "\n",
    "At level $\\alpha$, if the *p*-value for the $j$-th coefficient is less than $\\alpha$, then we reject the null hypothesis that the $j$-th coefficient is zero, i.e.,\n",
    "\n",
    "**We can look at the significance of all of the coefficients!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1743dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "845f52bb",
   "metadata": {},
   "source": [
    "## Type 2: Analysis of Variance\n",
    "Very complciated, usually there are a few cources that covers the detials of ANOVA.\n",
    "\n",
    "- We will only get some key `intuition` here for using ANOVA.\n",
    "- It is based from **sums of squares**.\n",
    "\n",
    "We need to go back to sum of squares and sum of residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39cbf6",
   "metadata": {},
   "source": [
    "### Sum of Squares\n",
    "\n",
    "We have three main quantities that are used to evaluate the goodness of fit of the regression model:\n",
    "\n",
    "| Quantity | Description |\n",
    "|----------|------------|\n",
    "| $y$     | Observed values of the dependent variable |\n",
    "| $\\hat{y}$ | Predicted values of the dependent variable |\n",
    "| $\\bar{y}$ | Mean of the observed values of the dependent variable |\n",
    "\n",
    "Your regression line has to path through the means of the data, the mean of $\\hat{y}$ will be thes ame with mean of $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f9ec1",
   "metadata": {},
   "source": [
    "Based on this, we have three important **sums of squares** in the regression model:\n",
    "\n",
    "| Sum of squares | Equation | Intuition |\n",
    "|---------------|----------|-----------|\n",
    "| $SS_{\\text{Tot}}$ | $\\sum\\limits_{i=1}^{n} (y_i - \\bar{y})^2$ | How much variability is present in the observed values $y$ |\n",
    "| $SS_{\\text{Reg}}$ | $\\sum\\limits_{i=1}^{n} (\\hat{y}_i - \\bar{y})^2$ | How much variability the regression model $\\hat{y}$ reproduces |\n",
    "| $SS_{\\text{Res}}$ | $\\sum\\limits_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | How much variability in $y$ the regression model $\\hat{y}$ is unable to reproduce |\n",
    "\n",
    "- $SS_{\\text{Reg}}$ + $SS_{\\text{Res}}$ should be smaller than $SS_{\\text{Tot}}$. Think of a triangle where $SS_{\\text{Reg}}$ is the base.\n",
    "- Hence we want a **triangle with smaller base**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b94418c",
   "metadata": {},
   "source": [
    "### F-Statistic\n",
    "\n",
    "The *F*-statistic is a measure of how well the model explains the variance in the data. It is given by:\n",
    "\n",
    "$$\n",
    "\\hat{F} = \\frac{SS_{\\text{Reg}} / \\text{df}_{\\text{Reg}}}{SS_{\\text{Res}} / \\text{df}_{\\text{Res}}}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\text{df}_{\\text{Reg}} = 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{df}_{\\text{Res}} = n - p - 1\n",
    "$$\n",
    "\n",
    "Intuitively, the *F*-statistic is the **ratio** of the explained variance to the unexplained variance in the data.\n",
    "\n",
    "The *F*-statistic is used to test the null hypothesis that the model is no better than the null model, i.e., the model with no predictors.\n",
    "\n",
    "$$\n",
    "H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: \\text{At least one } \\beta_j \\neq 0\n",
    "$$\n",
    "\n",
    "The *F*-statistic follows an $F(\\text{df}_{\\text{Reg}}, \\text{df}_{\\text{Res}})$ distribution under the null hypothesis, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{F} = \\frac{SS_{\\text{Reg}} / \\text{df}_{\\text{Reg}}}{SS_{\\text{Res}} / \\text{df}_{\\text{Res}}} \\sim F(\\text{df}_{\\text{Reg}}, \\text{df}_{\\text{Res}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3506af",
   "metadata": {},
   "source": [
    "> ANOVA is the doing like a `goodness of fit` test on all the variables of the F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652264fa",
   "metadata": {},
   "source": [
    "### Analysis of Variance (ANOVA)\n",
    "\n",
    "ANOVA is a method used to test whether the inclusion of a set of variables in a model significantly improves the model fit (among other things...).\n",
    "\n",
    "### Setting:\n",
    "\n",
    "Suppose we have two models: **we have one full model, then a `subset` od the big model, we want to see whether there is actually a improvement in the fit of data.**\n",
    "\n",
    "**Small model:**\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_1 + \\beta_3 x_3 + \\beta_{p-1} x_{p-1} + \\epsilon_i\n",
    "$$\n",
    "\n",
    "**Big model:**\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\dots + \\beta_p x_p + \\epsilon_i\n",
    "$$\n",
    "\n",
    "i.e.,\n",
    "\n",
    "- Small model: $(\\beta_0, \\beta_1, \\beta_3, \\beta_{p-1})$\n",
    "- Big model: $(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\dots, \\beta_p)$\n",
    "\n",
    "The idea is that **does having a bigger model give you more power to explain the variance (how much explanatory power does your big model has in relative to the smaller model)?** We look at it from three perspective\n",
    "- `Extra variance explained`\n",
    "- `Extra degree of freedom needed`\n",
    "- `Extra residual caused`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446fce4",
   "metadata": {},
   "source": [
    "### Method:\n",
    "\n",
    "- How much excess variance is explained by the inclusion of variables in the Big Model?\n",
    "\n",
    "  **Answer:**\n",
    "  $$\n",
    "  SS_{\\text{Reg}}(\\text{Small Model}) - SS_{\\text{Reg}}(\\text{Big Model})\n",
    "  $$\n",
    "\n",
    "- How many degrees of freedom are used up by the inclusion of variables in the Big Model?\n",
    "\n",
    "  **Answer:**\n",
    "  $$\n",
    "  \\Delta \\text{df} = \\text{df}_{\\text{Reg}}(\\text{Small Model}) - \\text{df}_{\\text{Reg}}(\\text{Big Model})\n",
    "  $$\n",
    "\n",
    "- How much residual variance is left after the inclusion of variables in the Big Model?\n",
    "\n",
    "  **Answer:**\n",
    "  $$\n",
    "  SS_{\\text{Res}}(\\text{Big Model})\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ef6e7",
   "metadata": {},
   "source": [
    "If the excess variance explained by the inclusion of $x_3, \\dots, x_p$ is large relative to the residual variance left after the inclusion of $x_3, \\dots, x_p$, then we conclude that the inclusion of $x_3, \\dots, x_p$ significantly improves the model fit, i.e.,\n",
    "\n",
    "$$\n",
    "\\hat{F} = \\frac{\\frac{SS_{\\text{Reg}}(\\text{Small Model}) - SS_{\\text{Reg}}(\\text{Big Model})}{\\Delta \\text{df}}}\n",
    "{\\frac{SS_{\\text{Res}}(\\text{Big Model})}{\\text{df}_{\\text{Res}}(\\text{Big Model})}}\n",
    "$$\n",
    "\n",
    "- Ths is a `generalization` of the F-test\n",
    "\n",
    "If $\\hat{F}$ is **LARGE**, then **including the variables** of the big model **significantly improves the model fit**. The rejection region for the ANOVA *F*-test is:\n",
    "\n",
    "$$\n",
    "(x_{\\alpha}, \\infty)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2b5d7",
   "metadata": {},
   "source": [
    "Techniqually, with this setup, you can have a **combinatorial** composition of nested smaller models!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f157045",
   "metadata": {},
   "source": [
    "## Type 3: How Regression Coefficients Relates to Each Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dabdbb",
   "metadata": {},
   "source": [
    "**Under the null hypotheiss, you have a belief that there are linear corrolation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339972a3",
   "metadata": {},
   "source": [
    "### General Linear Hypothesis Testing\n",
    "\n",
    "Suppose we want to test some general hypothesis about the coefficients, e.g.,\n",
    "\n",
    "$$\n",
    "H_0: 2\\beta_1 - 3\\beta_2 = 1 \\quad \\text{and} \\quad 3\\beta_0 + \\beta_1 + 4\\beta_2 = 100\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: 2\\beta_1 - 3\\beta_2 \\neq 1 \\quad \\text{OR} \\quad 3\\beta_0 + \\beta_1 + 4\\beta_2 \\neq 100\n",
    "$$\n",
    "\n",
    "This is called a **general linear hypothesis** and can be written in matrix form as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "0 & 2 & -3 \\\\ \n",
    "3 & 1 & 4 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "\\beta_0 \\\\ \n",
    "\\beta_1 \\\\ \n",
    "\\beta_2 \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "1 \\\\ \n",
    "100 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "More generally, suppose we want to test the hypothesis:\n",
    "\n",
    "$$\n",
    "H_0: R\\beta = q\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_a: R\\beta \\neq q\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $ R $ is a $ c \\times (p + 1) $ matrix of constants\n",
    "- $ q $ is a $ c \\times 1 $ vector of constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad940e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "646c5ed1",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb16e9c",
   "metadata": {},
   "source": [
    "# Interaction Terms: what happens when having nonlinear data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e111f",
   "metadata": {},
   "source": [
    "**we have shown eralier that maybe we can use transformation (i.e. log transformation) to solve some easy condisitions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce8a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc085603",
   "metadata": {},
   "source": [
    "The objective of adding an interaction term is to capture different orders of derivative information (i.e. second order interaction term captures second order derivative terms). More interatcions, we can capture more non-linear interactions by seeing how `covariate` interact with the `responses`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa4865",
   "metadata": {},
   "source": [
    "### Interaction: Categorical $\\times$ Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac371164",
   "metadata": {},
   "source": [
    "Assuming we want to dit the following model using **dummy variables**:\n",
    "\n",
    "$$\n",
    "E(y|x_1, x_2) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2\n",
    "$$\n",
    "\n",
    "For simplicity, suppose the term $ x_2 \\in \\{0,1\\} $ is a **categorical variable**. Then the interpretation of the coefficient $ \\beta_3 $ is as follows:\n",
    "\n",
    "> Case: categorical $ x_2 = 0 $\n",
    "$$\n",
    "E(y|x_1, x_2 = 0) = \\beta_0 + \\beta_1 x_1\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\frac{\\partial}{\\partial x_1} E(y|x_1, x_2 = 0) = \\beta_1\n",
    "$$\n",
    "\n",
    "We can take teh derivative to get one coefficient.\n",
    "\n",
    "> Case: categorical $ x_2 = 1 $\n",
    "$$\n",
    "E(y|x_1, x_2 = 1) = \\beta_0 + \\beta_1 x_1 + \\beta_2 + \\beta_3 x_1\n",
    "$$\n",
    "$$\n",
    "= (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3)x_1\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\frac{\\partial}{\\partial x_1} E(y|x_1, x_2 = 1) = \\beta_1 + \\beta_3\n",
    "$$\n",
    "\n",
    "Similar as above, we can take another derivative to get the other coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25ea3f",
   "metadata": {},
   "source": [
    "> Hence, we can say that:\n",
    "\n",
    "$$\n",
    "\\beta_3 = \\left[ \\frac{\\partial}{\\partial x_1} E(y|x_1, x_2 = 1) \\right] - \\left[ \\frac{\\partial}{\\partial x_1} E(y|x_1, x_2 = 0) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_3 = (\\beta_1 + \\beta_3) - \\beta_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_3 = \\frac{\\partial^2}{\\partial x_1 \\partial x_2} E(y | x_1, x_2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta_3 = \\text{the infinite-decimal change in the effect of } x_1 \\text{ on } y \\text{ when } x_2 \\text{ increases from 0 to 1.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb32e5",
   "metadata": {},
   "source": [
    "$ \\beta_3 $ represents the **interaction effect** between $ x_1 $ and $ x_2 $. It quantifies **how much the effect of $ x_1 $ on $ y $ changes when $ x_2 $ increases from 0 to 1**.\n",
    "\n",
    "- If $ \\beta_3 $ is significantly different from zero, it suggests that the relationship between $ x_1 $ and $ y $ depends on the value of $ x_2 $.\n",
    "\n",
    "- **In another word, it captures the gradient of $x_1$ with resect to changes in the $x_2$ variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99737ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "503290f4",
   "metadata": {},
   "source": [
    "The interatcion between $x_1$ and $x_2$ is atrteing to including **curvatures** and **saddle point infromations**, you can capture mroe than just fistting a plain on it. Depends on the **order** of your interactions, you can capture differnt trends.\n",
    "\n",
    "- When linearrity is insufficient to capture, you can capture the relationships between $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02221e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f38ed4e",
   "metadata": {},
   "source": [
    "### Interaction: Numeric $\\times$ Numeric\n",
    "\n",
    "Now with continuous scale, we can essentially model the original changes with another **partial derivative**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90fd52",
   "metadata": {},
   "source": [
    "More generally, the **interaction term $ \\beta_{i:j} $**, which is the coefficient of the term $ x_i x_j $ in the model, is interpreted as the second order partial derivatives:\n",
    "\n",
    "$$\n",
    "\\beta_{i:j} = \\frac{\\partial^2}{\\partial x_j \\partial x_i} E(y | x_1, x_2)\n",
    "$$\n",
    "\n",
    "When $ x_1 $ and $ x_2 $ are continuous, it has the effect of bringing in some curvature (nonlinear effect) into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98bdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eb3e101",
   "metadata": {},
   "source": [
    "### Higher Order Terms\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a3cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f15473cf",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b025551",
   "metadata": {},
   "source": [
    "# Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a2974",
   "metadata": {},
   "source": [
    "When you incorporate so many interaction terms to the point where you may have varaible interaction terms that are not independent any more, you face the issue of `multicollinearity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f1807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d263628",
   "metadata": {},
   "source": [
    "### Multicollinearity Intuition\n",
    "\n",
    "Intuitively, it is impossible to make an **infinite-decimal changes** in one of your covariate variable $x_i$ to cause changes in teh response variable $y$ while holding everything else constant (if one thing changes, the other covariate variable must also changes).\n",
    "\n",
    "- Making one unit change or any change in $x_1$ would cause chnage in $y$ as will as in $x_2$ and $x_3$.\n",
    "\n",
    "\n",
    "### Issues ⚠️\n",
    "In the regression model, the effect of multicollinearity would cause:\n",
    "\n",
    "- our model to not show significance response when there are actually significiance responses existing!\n",
    "\n",
    "- The **sensitivity** values is incorrect, the coefficient are meaningless from a regression model in this case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b97147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6020e6",
   "metadata": {},
   "source": [
    "### Multicollinearity Detection\n",
    "\n",
    "We can identify it through `corrolation table` or `variance inflation factor`. Consider the regression model:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n",
    "$$\n",
    "\n",
    "but $ x_1 $ and $ x_2 $ are related via the relationship:\n",
    "\n",
    "$$\n",
    "x_1 = 10 - x_2 + \\eta \\quad \\text{where} \\quad \\eta \\sim N(0, \\tau^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80beb5",
   "metadata": {},
   "source": [
    "> You can diagnose multicollinearity by looking at the **Variance Inflation Factor (VIF)** of each predictor.\n",
    ">\n",
    "> *The idea of the VIF is to quantify how much the variance of the estimated coefficient* $ \\hat{\\beta}_j $ *is inflated due to multicollinearity.*  \n",
    "> *This is related to the matrix* $ (X^T X)^{-1} $ *we encountered for the regression coefficients* $ \\hat{\\beta} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0843e20",
   "metadata": {},
   "source": [
    "Intuitively, we create another smaller `regression model` for **each of the covariate variable** as the **response** of every single else covaraite varaibles in the model. Then we calculate teh $R^2$ of the model.\n",
    "\n",
    "- If $R^2$ is high, this means that the rest covaraite variable is very corrolated with this covaraite varaible, the VIF is very high, showing multicollinearity.\n",
    "    - If VIF is greater than 5, it pretty much shows multicolineaity\n",
    "    - VIF is always greater or equal to 1\n",
    "\n",
    "- Then we just delete the highest VIF variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba22cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6cbdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee525856",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab4e41",
   "metadata": {},
   "source": [
    "# Regression For Categorical Response\n",
    "\n",
    "Previously we are all talking about things on the covariate scale, now we wnat to see on the response scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a998da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b4d65de",
   "metadata": {},
   "source": [
    "> #### Issue with treating $y$ as a standard quantiative response\n",
    "The linear regression model will give us a predicted value for the response variable for any given value of the predictor variable, but this predicted value is **not a probability**. The predicted value can take on any value between 0 and 1, but it doesn’t necessarily represent the probability of the response variable being a 1.\n",
    "\n",
    "**We need to have a model that give in faithful of our response varaible.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f63cc7",
   "metadata": {},
   "source": [
    "> #### Remedy for the case when $y$ is binary categorical\n",
    "\n",
    "We need a model that can give us the probability of the response variable being a 1 for any given value of the predictor variables. That is, we want a model which, when given a set of independent variables $x_1, x_2, \\dots, x_p$, will give us:\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, \\dots, x_p)\n",
    "$$\n",
    "\n",
    "the probability that the dependent variable $y$ is a 1.\n",
    "\n",
    "$$\n",
    "(x_1, x_2, \\dots, x_p) \\mapsto p(x_1, x_2, \\dots, x_p)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, \\dots, x_p) = \\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)\n",
    "$$\n",
    "\n",
    "Let's look like the world of `Odds`, it is a different way of looking at probability -> it is a very different but a more intuitive paradim compared to probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ce914",
   "metadata": {},
   "source": [
    "> #### Odds\n",
    "\n",
    "Consider the stock price of a famous GPU manufacturer whose valuation recently hit $2$ trillion.\n",
    "\n",
    "Suppose there’s a $0.7$ probability that the stock price will go down tomorrow, and a $0.3$ probability that the stock price will go up tomorrow.\n",
    "\n",
    "We have the following basic table:\n",
    "\n",
    "| Outcome | Probability |\n",
    "|---------|------------|\n",
    "| Up      | 0.3        |\n",
    "| Down    | 0.7        |\n",
    "\n",
    "The odds of the stock price going up tomorrow is:\n",
    "\n",
    "$$\n",
    "\\frac{\\mathbb{P}(\\text{Up})}{\\mathbb{P}(\\text{Down})} = \\frac{0.3}{0.7} = \\frac{3}{7}\n",
    "$$\n",
    "\n",
    "In general, given an event $A$, which occurs with probability $\\mathbb{P}(A)$:\n",
    "\n",
    "| Outcome | Probability        |\n",
    "|---------|--------------------|\n",
    "| $A$     | $\\mathbb{P}(A)$    |\n",
    "| $A^c$   | $1 - \\mathbb{P}(A)$ |\n",
    "\n",
    "The odds of $A$ is:\n",
    "\n",
    "$$\n",
    "\\text{odds}(A) = \\frac{\\mathbb{P}(A)}{\\mathbb{P}(A^c)} = \\frac{\\mathbb{P}(A)}{1 - \\mathbb{P}(A)}\n",
    "$$\n",
    "\n",
    "Notice that it is like **changing the absoluteness of probability into a relative standard**，odds takes in\n",
    "\n",
    "$$\n",
    "(0, \\infty)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65350648",
   "metadata": {},
   "source": [
    "> #### log-Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc15fd5",
   "metadata": {},
   "source": [
    "> #### Logistic Function\n",
    "\n",
    "Notice that this is how `Statistics` dervied out logistic regression!!! Remanber in `Deep Learning` logistic coems out from Bayes + Gaussian assumption.\n",
    "\n",
    "\n",
    "Given the independent variables $x_1, x_2, \\dots, x_p$, consider the event:\n",
    "\n",
    "$$\n",
    "A = \\{ y = 1 \\mid x_1, x_2, \\dots, x_p \\}.\n",
    "$$\n",
    "\n",
    "The log-odds of $A$ is:\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(\\{ y = 1 \\mid x_1, x_2, \\dots, x_p \\}) = \\log \\frac{\\mathbb{P}(A)}{\\mathbb{P}(A^c)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\log \\left( \\frac{\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)}{\\mathbb{P}(y = 0 \\mid x_1, x_2, \\dots, x_p)} \\right)\n",
    "$$\n",
    "\n",
    "Instead of modeling the probability of the response variable directly:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "logistic regression models the **log-odds** of the response variable:\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268b640",
   "metadata": {},
   "source": [
    "*Okay, so how do I get the probability?* 😏\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\text{odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\exp \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)}{\\mathbb{P}(y = 0 \\mid x_1, x_2, \\dots, x_p)} = \\exp \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow \\frac{\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)}{1 - \\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)} = \\exp \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ad326",
   "metadata": {},
   "source": [
    "By solving for $\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p)$, we get:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p) =\n",
    "\\frac{\\exp \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)}\n",
    "{1 + \\exp \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4159cf",
   "metadata": {},
   "source": [
    "> #### Logistic Regression\n",
    "The way logistic regression remedies the issue of standard regression for a categorical response is to use `Odds` and assuming data coming from a `bernulli` distribution.\n",
    "\n",
    "- Logistic regression models the **odds** of the response variable being a 1 as a linear function of the predictor variables.\n",
    "\n",
    "  $$\n",
    "  \\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "  $$\n",
    "\n",
    "- The probability of the response variable being a 1 is given by the **logistic function** of the linear combination of the predictor variables.\n",
    "\n",
    "  $$\n",
    "  \\mathbb{P}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\sigma \\left( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\right)\n",
    "  $$\n",
    "\n",
    "- The function which bridges the gap between the log-odds and the probability is called the **logistic function**, or the **sigmoid function**.\n",
    "\n",
    "- All of these is about how you fit to what data distribution you have! This `CDF` function may changes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8c53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2999732f",
   "metadata": {},
   "source": [
    "> #### Interpretation of the coefficients\n",
    "The interprettaion of it comes from a log scale. Given the logistic regression model:\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "The partial derivative of the log-odds with respect to \\( x_i \\) is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i} \\text{log-odds}(y = 1 \\mid x_1, x_2, \\dots, x_p) = \\beta_i\n",
    "$$\n",
    "\n",
    "This means that the coefficient \\( \\beta_i \\) is the expected change in the log-odds of the response variable for an infinitesimal change in \\( x_i \\), holding all other variables constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2054701",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
